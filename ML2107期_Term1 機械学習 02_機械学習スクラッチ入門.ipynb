{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "872c2ecf",
   "metadata": {},
   "source": [
    "## 【問題1】train_test_split のスクラッチ\n",
    "まずは、scikit-learnの train_test_split をスクラッチしてみます。以下の雛形をベースに関数を実装してください。<br>\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html<br>\n",
    "なお、作成した関数がscikit-learnの train_test_split と同じ動作をするか必ず確認をしましょう。<br>\n",
    "\n",
    "### 雛形\n",
    "```\n",
    "def scratch_train_test_split(X, y, train_size=0.8):\n",
    "    \"\"\"検証データを分割する。\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray\n",
    "      訓練データ (n_samples, n_features)\n",
    "    y : ndarray\n",
    "      正解値 (n_samples,)\n",
    "    train_size : float\n",
    "      何割をtrainとするか指定 (0 < train_size < 1)\n",
    "    Returns\n",
    "    -------\n",
    "    X_train : ndarray\n",
    "      訓練データ (n_samples, n_features)\n",
    "    X_test : ndarray\n",
    "      検証データ (n_samples, n_features)\n",
    "    y_train : ndarray\n",
    "      訓練データの正解値 (n_samples,)\n",
    "    y_test : ndarray\n",
    "      検証データの正解値 (n_samples,)\n",
    "    \"\"\"\n",
    "    # ここにコードを書く\n",
    "    pass\n",
    "    return X_train, X_test, y_train, y_test\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "411140a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "[[ 9 10 11]]\n",
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "[[ 9 10 11]]\n",
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "[[ 9 10 11]]\n",
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "[[ 9 10 11]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def scratch_train_test_split(X, y, train_size=0.8):\n",
    "    \"\"\"検証データを分割する。\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray\n",
    "      訓練データ (n_samples, n_features)\n",
    "    y : ndarray\n",
    "      正解値 (n_samples,)\n",
    "    train_size : float\n",
    "      何割をtrainとするか指定 (0 < train_size < 1)\n",
    "    Returns\n",
    "    -------\n",
    "    X_train : ndarray\n",
    "      訓練データ (n_samples, n_features)\n",
    "    X_test : ndarray\n",
    "      検証データ (n_samples, n_features)\n",
    "    y_train : ndarray\n",
    "      訓練データの正解値 (n_samples,)\n",
    "    y_test : ndarray\n",
    "      検証データの正解値 (n_samples,)\n",
    "    \"\"\"\n",
    "    # 戻り値計算\n",
    "    X_train, X_test = np.split(X, [int(X.shape[0]*train_size)])\n",
    "    y_train, y_test = np.split(y, [int(y.shape[0]*train_size)])\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X = np.arange(12).reshape((4, 3))\n",
    "y = np.arange(12).reshape((4, 3))\n",
    "\n",
    "s_X_train, s_X_test, s_y_train, s_y_test = scratch_train_test_split(X, y, train_size=0.8)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, shuffle=False)\n",
    "\n",
    "print(s_X_train)\n",
    "print(s_X_test)\n",
    "print(s_y_train)\n",
    "print(s_y_test)\n",
    "print(X_train)\n",
    "print(X_test)\n",
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ad04e4",
   "metadata": {},
   "source": [
    "## 【問題2】 分類問題を解くコードの作成\n",
    "### 分類問題\n",
    "分類は3種類の手法をscikit-learnを使って実装します。<br>\n",
    "　・ロジスティック回帰<br>\n",
    "　・SVM<br>\n",
    "　・決定木<br>\n",
    "<br>\n",
    "3種類のデータセットを用いて動作を確認します。<br>\n",
    "　・1つ目は事前学習期間同様のirisデータセットです。<br>\n",
    "　　2値分類としたいため、以下の2つの目的変数のみ利用します。特徴量は4種類すべて使います。<br>\n",
    "　　「virgicolor」「virginica」<br>\n",
    "　・シンプルデータセット1<br>\n",
    "　・シンプルデータセット2<br>\n",
    "上記3種類の手法で3種類のデータセットを学習・推定するコードを作成してください。<br>\n",
    "\n",
    "```\n",
    "# シンプルデータセット1 作成コード\n",
    "import numpy as np\n",
    "np.random.seed(seed=0)\n",
    "n_samples = 500\n",
    "f0 = [-1, 2]\n",
    "f1 = [2, -1]\n",
    "cov = [[1.0,0.8], [0.8, 1.0]]\n",
    "f0 = np.random.multivariate_normal(f0, cov, n_samples // 2)\n",
    "f1 = np.random.multivariate_normal(f1, cov, n_samples // 2)\n",
    "X = np.concatenate([f0, f1])\n",
    "y = np.concatenate([\n",
    "    np.full(n_samples // 2, 1),\n",
    "    np.full(n_samples // 2, -1)\n",
    "])\n",
    "```\n",
    "\n",
    "```\n",
    "# シンプルデータセット2 作成コード\n",
    "X = np.array([\n",
    "    [-0.44699 , -2.8073  ],[-1.4621  , -2.4586  ],\n",
    "    [ 0.10645 ,  1.9242  ],[-3.5944  , -4.0112  ],\n",
    "    [-0.9888  ,  4.5718  ],[-3.1625  , -3.9606  ],\n",
    "    [ 0.56421 ,  0.72888 ],[-0.60216 ,  8.4636  ],\n",
    "    [-0.61251 , -0.75345 ],[-0.73535 , -2.2718  ],\n",
    "    [-0.80647 , -2.2135  ],[ 0.86291 ,  2.3946  ],\n",
    "    [-3.1108  ,  0.15394 ],[-2.9362  ,  2.5462  ],\n",
    "    [-0.57242 , -2.9915  ],[ 1.4771  ,  3.4896  ],\n",
    "    [ 0.58619 ,  0.37158 ],[ 0.6017  ,  4.3439  ],\n",
    "    [-2.1086  ,  8.3428  ],[-4.1013  , -4.353   ],\n",
    "    [-1.9948  , -1.3927  ],[ 0.35084 , -0.031994],\n",
    "    [ 0.96765 ,  7.8929  ],[-1.281   , 15.6824  ],\n",
    "    [ 0.96765 , 10.083   ],[ 1.3763  ,  1.3347  ],\n",
    "    [-2.234   , -2.5323  ],[-2.9452  , -1.8219  ],\n",
    "    [ 0.14654 , -0.28733 ],[ 0.5461  ,  5.8245  ],\n",
    "    [-0.65259 ,  9.3444  ],[ 0.59912 ,  5.3524  ],\n",
    "    [ 0.50214 , -0.31818 ],[-3.0603  , -3.6461  ],\n",
    "    [-6.6797  ,  0.67661 ],[-2.353   , -0.72261 ],\n",
    "    [ 1.1319  ,  2.4023  ],[-0.12243 ,  9.0162  ],\n",
    "    [-2.5677  , 13.1779  ],[ 0.057313,  5.4681  ],\n",
    "])\n",
    "y = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "93caa078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "### irisデータセットの作成\n",
    "# irisのデータセットを読み込む\n",
    "data = load_iris()\n",
    "# 読み込んだデータセットをdataframeへ置き換える\n",
    "p_data_x = pd.DataFrame(data.data)\n",
    "p_data_y = pd.DataFrame(data.target)\n",
    "# dataframeを結合し、カラム名を設定する\n",
    "df_default = pd.concat([p_data_x, p_data_y],axis=1)\n",
    "df_default = df_default.set_axis([\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\",\"Species\"], axis=\"columns\")\n",
    "# 今回使用しないカラムと行を削除\n",
    "df_d_index = df_default.index[p_data_y[0] == 0]\n",
    "df = df_default.drop(df_d_index)\n",
    "# indexを振りなおす\n",
    "df = df.reset_index(drop=\"True\")\n",
    "# 元のデータフレームから特徴量（説明変数）のみ、正解（目的変数）のみ、となるようにデータフレームを作成し、ndarrayに変換\n",
    "X_iris = df.drop(\"Species\", axis=1).values\n",
    "y_iris = df.drop([\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\"], axis=1).values\n",
    "\n",
    "### シンプルデータセット1の作成\n",
    "# シンプルデータセット1 作成コード\n",
    "np.random.seed(seed=0)\n",
    "n_samples = 500\n",
    "f0 = [-1, 2]\n",
    "f1 = [2, -1]\n",
    "cov = [[1.0,0.8], [0.8, 1.0]]\n",
    "f0 = np.random.multivariate_normal(f0, cov, n_samples // 2)\n",
    "f1 = np.random.multivariate_normal(f1, cov, n_samples // 2)\n",
    "X_smp1 = np.concatenate([f0, f1])\n",
    "y_smp1 = np.concatenate([\n",
    "    np.full(n_samples // 2, 1),\n",
    "    np.full(n_samples // 2, -1)\n",
    "])\n",
    "\n",
    "### シンプルデータセット2の作成\n",
    "# シンプルデータセット2 作成コード\n",
    "X_smp2 = np.array([\n",
    "    [-0.44699 , -2.8073  ],[-1.4621  , -2.4586  ],\n",
    "    [ 0.10645 ,  1.9242  ],[-3.5944  , -4.0112  ],\n",
    "    [-0.9888  ,  4.5718  ],[-3.1625  , -3.9606  ],\n",
    "    [ 0.56421 ,  0.72888 ],[-0.60216 ,  8.4636  ],\n",
    "    [-0.61251 , -0.75345 ],[-0.73535 , -2.2718  ],\n",
    "    [-0.80647 , -2.2135  ],[ 0.86291 ,  2.3946  ],\n",
    "    [-3.1108  ,  0.15394 ],[-2.9362  ,  2.5462  ],\n",
    "    [-0.57242 , -2.9915  ],[ 1.4771  ,  3.4896  ],\n",
    "    [ 0.58619 ,  0.37158 ],[ 0.6017  ,  4.3439  ],\n",
    "    [-2.1086  ,  8.3428  ],[-4.1013  , -4.353   ],\n",
    "    [-1.9948  , -1.3927  ],[ 0.35084 , -0.031994],\n",
    "    [ 0.96765 ,  7.8929  ],[-1.281   , 15.6824  ],\n",
    "    [ 0.96765 , 10.083   ],[ 1.3763  ,  1.3347  ],\n",
    "    [-2.234   , -2.5323  ],[-2.9452  , -1.8219  ],\n",
    "    [ 0.14654 , -0.28733 ],[ 0.5461  ,  5.8245  ],\n",
    "    [-0.65259 ,  9.3444  ],[ 0.59912 ,  5.3524  ],\n",
    "    [ 0.50214 , -0.31818 ],[-3.0603  , -3.6461  ],\n",
    "    [-6.6797  ,  0.67661 ],[-2.353   , -0.72261 ],\n",
    "    [ 1.1319  ,  2.4023  ],[-0.12243 ,  9.0162  ],\n",
    "    [-2.5677  , 13.1779  ],[ 0.057313,  5.4681  ],\n",
    "])\n",
    "y_smp2 = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "# print(X, y)\n",
    "\n",
    "# train_test_splitにX、yを代入（デフォルト(指定なし)で訓練75%、検証25%となる）\n",
    "X_iris_train, X_iris_test, y_iris_train, y_iris_test = scratch_train_test_split(X_iris, y_iris)\n",
    "X_smp1_train, X_smp1_test, y_smp1_train, y_smp1_test = scratch_train_test_split(X_smp1, y_smp1)\n",
    "X_smp2_train, X_smp2_test, y_smp2_train, y_smp2_test = scratch_train_test_split(X_smp2, y_smp2)\n",
    "\n",
    "# またしても・・・警告回避\n",
    "y_iris_train = y_iris_train.reshape(80,)\n",
    "y_iris_test = y_iris_test.reshape(20,)\n",
    "\n",
    "# インスタンス化\n",
    "scaler_iris = StandardScaler()\n",
    "scaler_smp1 = StandardScaler()\n",
    "scaler_smp2 = StandardScaler()\n",
    "\n",
    "# 訓練用のデータのみを.fitで標準化\n",
    "scaler_iris.fit(X_iris_train)\n",
    "scaler_smp1.fit(X_smp1_train)\n",
    "scaler_smp2.fit(X_smp2_train)\n",
    "\n",
    "# 訓練用、検証用双方のデータにtransformで標準化\n",
    "tr_X_iris_train = scaler_iris.transform(X_iris_train)\n",
    "tr_X_smp1_train = scaler_smp1.transform(X_smp1_train)\n",
    "tr_X_smp2_train = scaler_smp2.transform(X_smp2_train)\n",
    "tr_X_iris_test = scaler_iris.transform(X_iris_test)\n",
    "tr_X_smp1_test = scaler_smp1.transform(X_smp1_test)\n",
    "tr_X_smp2_test = scaler_smp2.transform(X_smp2_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "849d652c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== ロジスティック回帰 ==========\n"
     ]
    }
   ],
   "source": [
    "# ロジスティック回帰\n",
    "print(\"========== ロジスティック回帰 ==========\")\n",
    "# 学習\n",
    "clf_iris = LogisticRegression(random_state=0).fit(tr_X_iris_train, y_iris_train)\n",
    "clf_smp1 = LogisticRegression(random_state=0).fit(tr_X_smp1_train, y_smp1_train)\n",
    "clf_smp2 = LogisticRegression(random_state=0).fit(tr_X_smp2_train, y_smp2_train)\n",
    "# 推定\n",
    "Y_iris_pred_LR = clf_iris.predict(tr_X_iris_test)\n",
    "Y_smp1_pred_LR = clf_smp1.predict(tr_X_smp1_test)\n",
    "Y_smp2_pred_LR = clf_smp2.predict(tr_X_smp2_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "03d866f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== SVM ==========\n"
     ]
    }
   ],
   "source": [
    "print(\"========== SVM ==========\")\n",
    "# 学習\n",
    "clf_iris = make_pipeline(StandardScaler(), SVC(gamma='auto')).fit(X_iris_train,y_iris_train)\n",
    "clf_smp1 = make_pipeline(StandardScaler(), SVC(gamma='auto')).fit(X_smp1_train,y_smp1_train)\n",
    "clf_smp2 = make_pipeline(StandardScaler(), SVC(gamma='auto')).fit(X_smp2_train,y_smp2_train)\n",
    "# 推定\n",
    "Y_iris_pred_SVC = clf_iris.predict(tr_X_iris_test)\n",
    "Y_smp1_pred_SVC = clf_smp1.predict(tr_X_smp1_test)\n",
    "Y_smp2_pred_SVC = clf_smp2.predict(tr_X_smp2_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "66776089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== 決定木 ==========\n"
     ]
    }
   ],
   "source": [
    "print(\"========== 決定木 ==========\")\n",
    "# 学習\n",
    "clf_iris = DecisionTreeClassifier(random_state=0).fit(X_iris_train,y_iris_train)\n",
    "clf_smp1 = DecisionTreeClassifier(random_state=0).fit(X_smp1_train,y_smp1_train)\n",
    "clf_smp2 = DecisionTreeClassifier(random_state=0).fit(X_smp2_train,y_smp2_train)\n",
    "# 推定\n",
    "Y_iris_pred_DTC = clf_iris.predict(tr_X_iris_test)\n",
    "Y_smp1_pred_DTC = clf_smp1.predict(tr_X_smp1_test)\n",
    "Y_smp2_pred_DTC = clf_smp2.predict(tr_X_smp2_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fb86d9",
   "metadata": {},
   "source": [
    "## 【問題3】 回帰問題を解くコードの作成\n",
    "線形回帰でHouse Pricesデータセットを学習・推定するコードを作成してください。<br>\n",
    "\n",
    "### 線形回帰\n",
    "線形回帰は勾配降下法を用いて計算する SGDRegressor クラスを利用してください。<br>\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html<br>\n",
    "\n",
    "データセットは事前学習期間同様にHouse Pricesコンペティションのものを使います。<br>\n",
    "https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data<br>\n",
    "train.csvをダウンロードし、目的変数としてSalePrice、説明変数として、GrLivAreaとYearBuiltを使います。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "419cfbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[202928.38984856 415101.39127397 147732.22776908 142455.65180329\n",
      " 190537.15527385 311229.01413394 223368.93740064 337121.09191004\n",
      " 135556.4305198  106002.80384448 112687.1635931  124765.51797527\n",
      " 299553.40888495 232470.27908956 500358.99028019  90530.02692416\n",
      " 178433.55432674 103656.29083471 126494.42031698 215350.18607714\n",
      " 227117.38763842 238330.98079213 181345.4131784  202316.09426943\n",
      " 129583.58091373 180786.53400656 162752.95833212 209950.92067931\n",
      " 251355.68265239 141992.44380224 181644.82856498 159582.78727629\n",
      " 115360.68604125 234826.18204679 117280.97504923 222092.08141621\n",
      " 141317.91765894 268003.17771631 130312.14357953 232110.40483511\n",
      " 148736.11083762 231215.12627744 235227.73527421 221903.04223681\n",
      "  66602.88473108 119763.11083113 120559.17482538 114239.38430494\n",
      " 226540.88015278 199960.19131221  96560.98791123 151507.07615289\n",
      " 113976.37712705 147739.27022967 191276.25946819 222097.35218048\n",
      " 212299.78117595 130252.26050221 259325.13675178 115000.81178681\n",
      " 237431.00726073 168911.30372496 296752.50203102 139509.15643925\n",
      " 142882.45159564 136237.42333314 164055.06088148 149269.74344454\n",
      " 224768.52714178 257740.05122387 178698.33320094 213753.36311492\n",
      " 238856.9951479  235116.78327647 150115.7247781  272488.38466157\n",
      " 138145.9749068  229314.19295491 219574.73333138 138373.76978176\n",
      " 179527.83780181 107174.59871067 236933.1627473  202842.10862521\n",
      " 114303.96235598 248735.00082096 227744.96404448 125312.6597128\n",
      " 251365.07259984  66187.82237304 181178.69728653 133187.01843195\n",
      " 225532.30211051 119472.50960145 193717.29206767 158360.49928024\n",
      " 190973.34501365 203407.45446709 155589.53396497 268782.80930252\n",
      " 335776.69027249 168549.08198365 190062.20983849 175320.91886137\n",
      " 117282.74674554 153004.68455169  92191.42793742 197593.70250177\n",
      " 170092.48853859 197611.90660611 263925.9906685   90331.59779731\n",
      " 218485.72062059 182976.29686246 139993.49182205 211631.10158747\n",
      " 220171.17229302 137972.79234489 154225.20085143 180450.13462073\n",
      " 224969.30375549 261971.64093869 137787.87234867 160865.53414021\n",
      " 185070.3442229  200878.9447385   99994.16614494 131964.15464534\n",
      " 134382.28816675 171852.52832473 628336.38714892 141991.86801169\n",
      " 256090.38764492 149181.69052487 304841.72228505 225825.25082706\n",
      " 233928.55600225 230421.40977005 201220.03909805 152448.15286671\n",
      " 118420.48088989 179536.07616816 207076.62161744 191893.87013625\n",
      " 328920.91965828 317206.55871373 107303.75481275 238156.0265339\n",
      " 230287.55869425 200657.04074303 238693.20253344 107303.75481275\n",
      " 162960.77740641  79560.66105344 242966.47122123  69150.17435457\n",
      " 244609.0923396   59441.23206025  66478.42360273 122891.60291398\n",
      " 255424.63133385 220241.64122355 224071.67771095 130436.60470789\n",
      "  77816.47788479 131789.20038712 165067.18231638 169162.57346853\n",
      " 197011.92425185  68686.39056298 247059.51488652 117409.55536076\n",
      " 117178.8372084  173970.670669   277617.60042093 176410.50736272\n",
      " 210975.35533907  73663.55114218 241497.03266478 242724.01563455\n",
      " 206550.03147112 163192.64713988 289946.02864092 191696.01679996\n",
      " 112509.28605746 376506.92610226 245407.50382071 218082.39569686\n",
      " 114040.95517809 137617.03727362 216436.85130108 260914.91725342\n",
      " 237499.08437973 217292.79837264 150852.48148559 206609.91454844\n",
      " 184551.99244292 226457.52220684 236941.9769042  183151.82691123\n",
      " 147579.59679838 228935.53880556 114738.38039947 179068.17319339\n",
      " 266376.41321543 322628.72318963 259756.63151786 223409.46479251\n",
      "  67041.42195775 159070.85784169 130637.3813216  204824.05240681\n",
      "  57992.34509501 239676.53401077 153233.63100775 116856.52274374\n",
      " 122693.74957769  94960.04576583 314048.12509222 224935.81882421\n",
      " 239747.57873185 120774.03636026 211674.55225675 183721.86772684\n",
      " 115859.10634523 152749.29562494 215340.7961297  311745.06275172\n",
      " 174476.70922412 128529.20471532 198055.1388065  143076.76153932\n",
      " 102527.9466378  222518.88120856 194902.59606447 212793.50650621\n",
      "  93741.87695295 227777.25307    107884.95727212 127651.55447145\n",
      " 103402.67360427 253686.33904468 243951.57439488 174640.50183858\n",
      " 111309.32134893 248446.17128759 164839.38744142 223211.03566566\n",
      " 169763.7074039  301399.15410389 135969.72118153 211566.52353643\n",
      " 168078.25573146 142870.71416133 147579.59679838 243912.81869932\n",
      " 150690.46056743 142587.15539224 265255.11147911 158604.72656323\n",
      "  78674.77244322 183777.05583043 247850.88390705 130833.46296158\n",
      "  81628.31026785 238164.8406908  148525.94427647 173936.60994717\n",
      " 116385.12070101 260250.35684811 138950.85305795 210004.33708659\n",
      " 233959.64912201 148604.03145813 267691.44910487  68772.09599578\n",
      " 205553.19086316 116124.46100998 139310.7273124  262608.6072922\n",
      " 101716.02602607  92144.47820018 211529.53953719 225128.40139623\n",
      " 171852.52832473 179623.55329727 185611.06361506 222754.29433465\n",
      " 243506.57049818 232092.77652131 116103.90941877 149130.62160446]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# ファイル名（パス）を指定する\n",
    "csv_path = \"E:/DiveIntoCode/source/train.csv\" # 絶対パス\n",
    "# 指数表示の禁止を設定する\n",
    "np.set_printoptions(suppress=True)\n",
    "# csvファイル読み込み\n",
    "df_train = pd.read_csv(csv_path)\n",
    "# Xに説明変数、yに目的変数となる列をそれぞれ抽出して代入\n",
    "X = df_train[[\"GrLivArea\",\"YearBuilt\"]].values\n",
    "y = df_train[\"SalePrice\"].values\n",
    "\n",
    "# train_test_splitにX、yを代入（デフォルト(指定なし)で訓練75%、検証25%となる）\n",
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X, y)\n",
    "\n",
    "# インスタンス化\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 訓練用のデータのみを.fitで標準化\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# 訓練用、検証用双方のデータにtransformで標準化\n",
    "tr_X_tarin = scaler.transform(X_train)\n",
    "tr_X_test = scaler.transform(X_test)\n",
    "\n",
    "# 線形回帰による学習\n",
    "reg = make_pipeline(StandardScaler(),SGDRegressor(max_iter=1000, tol=1e-3)).fit(tr_X_tarin, y_train)\n",
    "\n",
    "# 学習モデルによる推定\n",
    "Y_pred = reg.predict(tr_X_test)\n",
    "\n",
    "print(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fab70d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

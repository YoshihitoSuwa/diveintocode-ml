{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5940d93c",
   "metadata": {},
   "source": [
    "### 【問題1】仮定関数\n",
    "ロジスティック回帰の仮定関数のメソッドをScratchLogisticRegressionクラスに実装してください。<br>\n",
    "ロジスティック回帰の仮定関数は、線形回帰の仮定関数を シグモイド関数 に通したものです。シグモイド関数は以下の式で表されます。<br>\n",
    "<br>\n",
    "　　　　$ g(z) = \\displaystyle\\frac{1}{1+e^{-z}} $<br>\n",
    "<br>\n",
    "線形回帰の仮定関数は次の式でした。<br>\n",
    "<br>\n",
    "　　　　$ h_{\\theta}(x) = \\theta^T・x$<br>\n",
    "<br>\n",
    "まとめて書くと、ロジスティック回帰の仮定関数は次のようになります。<br>\n",
    "<br>\n",
    "　　　　$ h_{\\theta}(x) = \\displaystyle\\frac{1}{1+e^{-\\theta^T・x}} $<br>\n",
    "<br>\n",
    "　　　　$ x $ : 特徴量ベクトル<br>\n",
    "　　　　$ \\theta $ : パラメータ（重み）ベクトル<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "568626ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 問題７参照\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c29142",
   "metadata": {},
   "source": [
    "### 【問題2】最急降下法\n",
    "最急降下法により学習させる実装を行なってください。以下の式で表されるパラメータの更新式のメソッド_gradient_descentを追加し、fitメソッドから呼び出すようにしてください。<br>\n",
    "<br>\n",
    "　　　　$ \\theta_j := \\theta_j - \\alpha\\displaystyle\\frac{\\partial J(\\theta)}{\\partial\\theta_j} $<br>\n",
    "<br>\n",
    "　　　　$ \\displaystyle\\frac{\\partial J(\\theta)}{\\partial\\theta_0} = \\displaystyle\\frac{1}{m}\\displaystyle\\sum_{i=1}^{m}(h_{\\theta}(x^{(i)}) - y^{(i)})x_j^{(i)} ,　j = 0 $<br>\n",
    "<br>\n",
    "　　　　$ \\displaystyle\\frac{\\partial J(\\theta)}{\\partial\\theta_j} = (\\displaystyle\\frac{1}{m}\\displaystyle\\sum_{i=1}^{m}(h_{\\theta}(x^{(i)}) - y^{(i)})x_j^{(i)}) + \\displaystyle\\frac{\\lambda}{m}\\theta_j ,　j \\geqq 0 $<br>\n",
    "<br>\n",
    "　　　　$ \\alpha $ : 学習率<br>\n",
    "　　　　$ i $ : サンプルのインデックス<br>\n",
    "　　　　$ j $ : 特徴量のインデックス<br>\n",
    "　　　　$ m $ : 入力されるデータの数<br>\n",
    "　　　　$ h_{\\theta}() $ : 仮定関数<br>\n",
    "　　　　$ x $ : 特徴量ベクトル<br>\n",
    "　　　　$ \\theta $ : パラメータ（重み）ベクトル<br>\n",
    "　　　　$ x^{(i)} $ : i番目のサンプルの特徴量ベクトル<br>\n",
    "　　　　$ y^{(i)} $ : i番目のサンプルの正解ラベル<br>\n",
    "　　　　$ \\theta_j $ : j番目のパラメータ（重み）<br>\n",
    "　　　　$ \\lambda $ : 正則化パラメータ<br>\n",
    "<br>\n",
    "以上の式には正則化項が含まれます。正則化項は過学習を防ぐ目的で用いられます。<br>\n",
    "切片である$ \\theta_0 $が正則化項に含まれていないのは、切片を除いた特徴量に対する係数を同じ視点で議論することができるようにするためです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10860db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 問題７参照\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80c006e",
   "metadata": {},
   "source": [
    "### 【問題4】目的関数\n",
    "以下の数式で表されるロジスティック回帰の 目的関数（損失関数） を実装してください。そして、これをself.loss, self.val_lossに記録するようにしてください。<br>\n",
    "なお、この数式には正則化項が含まれています<br>\n",
    "<br>\n",
    "　　　　$ J(\\theta) = \\displaystyle\\frac{1}{m}\\displaystyle\\sum_{i=1}^{m}[-y^{(i)}\\log(h_{\\theta}(x^{(i)})) - (1 - y^{(i)}\\log(1 - h_{\\theta}(x^{(i)}))] +  $<br>\n",
    "<br>\n",
    "　　　　$ m $ : 入力されるデータの数<br>\n",
    "　　　　$ h_{\\theta}() $ : 仮定関数<br>\n",
    "　　　　$ x $ : 特徴量ベクトル<br>\n",
    "　　　　$ \\theta $ : パラメータ（重み）ベクトル<br>\n",
    "　　　　$ x^{(i)} $ : i番目のサンプルの特徴量ベクトル<br>\n",
    "　　　　$ y^{(i)} $ : i番目のサンプルの正解ラベル<br>\n",
    "　　　　$ \\theta_j $ : j番目のパラメータ（重み）<br>\n",
    "　　　　$ n $ : 特徴量の数<br>\n",
    "　　　　$ \\lambda $ : 正則化パラメータ<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d354403d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 問題７参照\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3493f76e",
   "metadata": {},
   "source": [
    "### 【問題5】学習と推定\n",
    "機械学習スクラッチ入門のSprintで用意したirisデータセットのvirgicolorとvirginicaの2値分類に対してスクラッチ実装の学習と推定を行なってください。<br>\n",
    "scikit-learnによる実装と比べ、正しく動いているかを確認してください。<br>\n",
    "AccuracyやPrecision、Recallなどの指標値はscikit-learnを使用してください。<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ff2896e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-d897c56909a4>:117: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_array = (np.sum((-1 * y * np.log(hypothesis_y)) - ((1 - y) * np.log(1 - hypothesis_y))) / X.shape[0]) \\\n",
      "<ipython-input-29-d897c56909a4>:117: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss_array = (np.sum((-1 * y * np.log(hypothesis_y)) - ((1 - y) * np.log(1 - hypothesis_y))) / X.shape[0]) \\\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " ...\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 295200 into shape (410,360)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-d897c56909a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[1;31m# # 可視化\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m \u001b[0mdecision_region\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-29-d897c56909a4>\u001b[0m in \u001b[0;36mdecision_region\u001b[1;34m(X, y, model, step, title, xlabel, ylabel, target_names)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[0mmesh_f0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmesh_f1\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeshgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[0mmesh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmesh_f0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmesh_f1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmesh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmesh_f0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[1;31m# plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 295200 into shape (410,360)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "class ScratchLogisticRegression():\n",
    "    \"\"\"\n",
    "    ロジスティック回帰のスクラッチ実装\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_iter : int\n",
    "      イテレーション数\n",
    "    lr : float\n",
    "      学習率\n",
    "    no_bias : bool\n",
    "      バイアス項を入れない場合はTrue\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.coef_ : 次の形のndarray, shape (n_features,)\n",
    "      パラメータ\n",
    "    self.loss : 次の形のndarray, shape (self.iter,)\n",
    "      訓練データに対する損失の記録\n",
    "    self.val_loss : 次の形のndarray, shape (self.iter,)\n",
    "      検証データに対する損失の記録\n",
    "    \"\"\"\n",
    "    def __init__(self, num_iter, lr, penalty, bias, verbose):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.bias = bias\n",
    "        self.verbose = verbose\n",
    "        # 損失を記録する配列を用意\n",
    "        self.loss = np.zeros(self.iter)\n",
    "        self.val_loss = np.zeros(self.iter)\n",
    "\n",
    "        # 正則化パラメータ(lambda) ここでは値とする\n",
    "        self.penalty = penalty\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ロジスティック回帰を学習する。検証データが入力された場合はそれに対する損失と精度もイテレーションごとに計算する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "#         if self.verbose:\n",
    "#             #verboseをTrueにした際は学習過程を出力\n",
    "#             print()\n",
    "\n",
    "        # Xの1列目に「1」を入れる\n",
    "        zeroplus_X = np.insert(X, 0, 1, axis = 1)\n",
    "\n",
    "        if X_val is not None:\n",
    "            # X_valの1列目に「1」を入れる\n",
    "            val_zeroplus_X = np.insert(X_val, 0, 1, axis = 1)\n",
    "\n",
    "        # ランダムな値をself.thetaの初期値に設定する\n",
    "        self.theta = np.random.random(len(zeroplus_X[0]))\n",
    "\n",
    "        for i in range(self.iter):\n",
    "#             print(\"{}回目ループ / 全{}回 \".format(i, self.iter))\n",
    "\n",
    "            # 仮定関数\n",
    "            hypothesis_y = self._logistic_hypothesis(zeroplus_X)\n",
    "\n",
    "            # errorの計算\n",
    "            error = hypothesis_y - y\n",
    "\n",
    "            # self.thetaの更新\n",
    "            self._gradient_descent(zeroplus_X, error)\n",
    "\n",
    "            # 損失関数の計算\n",
    "            self.loss[i] = self._loss_func(zeroplus_X, y, hypothesis_y)\n",
    "\n",
    "            if X_val is not None:\n",
    "                val_hypothesis_y = self._logistic_hypothesis(val_zeroplus_X)\n",
    "                val_error = val_hypothesis_y - y\n",
    "                self.val_loss[i] = self._loss_func(val_zeroplus_X, y_val, val_hypothesis_y)\n",
    "\n",
    "\n",
    "    def _logistic_hypothesis(self, X):\n",
    "\n",
    "        # 仮定のy\n",
    "        hypothesis_y = 1 / (1 + np.e ** (-1 * np.dot(self.theta.T,X.T)))\n",
    "\n",
    "        return hypothesis_y\n",
    "\n",
    "\n",
    "    def _gradient_descent(self, X, error):\n",
    "\n",
    "        # 切片の場合\n",
    "        self.theta[0] = self.theta[0] - self.lr * (np.sum(error@X[:,0])) / X.shape[0]\n",
    "        # 切片以外の場合\n",
    "        self.theta[1:] = self.theta[1:] - self.lr * ((np.sum(error@X[:,1:])) / X.shape[0]) + (self.penalty * self.theta[1:] / X.shape[0])\n",
    "\n",
    "\n",
    "    def _loss_func(self, X, y, hypothesis_y):\n",
    "#         print(\"np.log(hypothesis_y):{}\".format(np.log(hypothesis_y)))\n",
    "#         print(\"np.log(1 - hypothesis_y)):{}\".format(np.log(1 - hypothesis_y)))\n",
    "        loss_array = (np.sum((-1 * y * np.log(hypothesis_y)) - ((1 - y) * np.log(1 - hypothesis_y))) / X.shape[0]) \\\n",
    "                     + (self.penalty * np.sum(self.theta ** 2) / (2 * X.shape[0]))\n",
    "\n",
    "        return loss_array\n",
    "\n",
    "\n",
    "    def _calc_error(self, X, y):\n",
    "\n",
    "        hypothesis_y = self._logistic_hypothesis(X)\n",
    "        error = hypothesis_y - y\n",
    "\n",
    "        return error\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ロジスティック回帰を使いラベルを推定する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            ロジスティック回帰による推定結果\n",
    "        \"\"\"\n",
    "\n",
    "        # Xの1列目に「1」を入れる\n",
    "        zeroplus_X = np.insert(X, 0, 1, axis = 1)\n",
    "\n",
    "        # predict_probaにて、仮定関数の値を算出\n",
    "        predict_proba_y = self.predict_proba(zeroplus_X)\n",
    "\n",
    "        # 算出した値に対して閾値を設定し、「0」と「1」にラベル分けする\n",
    "        # 閾値を盲目的に 0.5 にしてもよいのか？それともprecision_recall_curve(多分閾値を出す関数）を使うのか\n",
    "        classification = []\n",
    "        for i in range(len(predict_proba_y)):\n",
    "            if predict_proba_y[i] >= 0.5:\n",
    "                classification.append(1)\n",
    "            else:\n",
    "                classification.append(0)\n",
    "#         for i in range(len(predict_proba_y[0])):\n",
    "#             for j in range(len(predict_proba_y[1])):\n",
    "#                 if predict_proba_y[i,j] >= 0.5:\n",
    "#                     classification.append(1)\n",
    "#                 else:\n",
    "#                     classification.append(0)\n",
    "#         nd_classification = np.array(classification).reshape(len(predict_proba_y),1)\n",
    "#         predict_y = np.concatenate([predict_proba_y, nd_classification], 1)\n",
    "        nd_classification = np.array(classification).reshape(len(predict_proba_y),1)\n",
    "        predict_proba_y = predict_proba_y.reshape(len(predict_proba_y),1)\n",
    "        predict_y = np.concatenate([predict_proba_y, nd_classification], 1)\n",
    "        print(predict_y)\n",
    "\n",
    "        return predict_y\n",
    "\n",
    "\n",
    "    def predict_proba(self, zeroplus_X):\n",
    "        \"\"\"\n",
    "        ロジスティック回帰を使い確率を推定する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            ロジスティック回帰による推定結果\n",
    "        \"\"\"\n",
    "\n",
    "        predict_proba_y = 1 / (1 + np.e ** (-1 * np.dot(self.theta.T,zeroplus_X.T)))\n",
    "\n",
    "        return predict_proba_y\n",
    "\n",
    "\n",
    "\n",
    "def decision_region(X, y, model, step=0.01, title='decision region', xlabel='xlabel', ylabel='ylabel', target_names=['versicolor', 'virginica']):\n",
    "    \"\"\"\n",
    "    2値分類を2次元の特徴量で学習したモデルの決定領域を描く。\n",
    "    背景の色が学習したモデルによる推定値から描画される。\n",
    "    散布図の点は訓練データまたは検証データである。\n",
    "\n",
    "    Parameters\n",
    "    ----------------\n",
    "    X : ndarray, shape(n_samples, 2)\n",
    "        特徴量\n",
    "    y : ndarray, shape(n_samples,)\n",
    "        ラベル\n",
    "    model : object\n",
    "        学習したモデルのインスンタスを入れる\n",
    "    step : float, (default : 0.1)\n",
    "        推定値を計算する間隔を設定する\n",
    "    title : str\n",
    "        グラフのタイトルの文章を与える\n",
    "    xlabel, ylabel : str\n",
    "        軸ラベルの文章を与える\n",
    "    target_names= : list of str\n",
    "        凡例の一覧を与える\n",
    "    \"\"\"\n",
    "    # setting\n",
    "    scatter_color = ['red', 'blue']\n",
    "    contourf_color = ['pink', 'skyblue']\n",
    "    n_class = 2\n",
    "    # pred\n",
    "    mesh_f0, mesh_f1  = np.meshgrid(np.arange(np.min(X[:,0])-0.5, np.max(X[:,0])+0.5, step), np.arange(np.min(X[:,1])-0.5, np.max(X[:,1])+0.5, step))\n",
    "    mesh = np.c_[np.ravel(mesh_f0),np.ravel(mesh_f1)]\n",
    "    y_pred = model.predict(mesh).reshape(mesh_f0.shape)\n",
    "\n",
    "    # plot\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.contourf(mesh_f0, mesh_f1, y_pred, n_class-1, cmap=ListedColormap(contourf_color))\n",
    "    plt.contour(mesh_f0, mesh_f1, y_pred, n_class-1, colors='y', linewidths=3, alpha=0.5)\n",
    "    for i, target in enumerate(set(y)):\n",
    "        plt.scatter(X[y==target][:, 0], X[y==target][:, 1], s=80, color=scatter_color[i], label=target_names[i], marker='o')\n",
    "    patches = [mpatches.Patch(color=scatter_color[i], label=target_names[i]) for i in range(n_class)]\n",
    "    plt.legend(handles=patches)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# irisのデータセットを読み込む\n",
    "data = load_iris()\n",
    "# 読み込んだデータセットをdataframeへ置き換える\n",
    "p_data_x = pd.DataFrame(data.data)\n",
    "p_data_y = pd.DataFrame(data.target)\n",
    "# dataframeを結合し、カラム名を設定する\n",
    "df_default = pd.concat([p_data_x, p_data_y],axis=1)\n",
    "df_default = df_default.set_axis([\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\",\"Species\"], axis=\"columns\")\n",
    "# 今回使用しないカラムと行を削除\n",
    "df_d_index = df_default.index[p_data_y[0] == 0]\n",
    "df = df_default.drop(df_d_index)\n",
    "# indexを振りなおす\n",
    "df = df.reset_index(drop=\"True\")\n",
    "X_iris = df.drop([\"sepal_width\",\"petal_width\",\"Species\"], axis=1).values\n",
    "y_iris = df.drop([\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\"], axis=1).values\n",
    "\n",
    "# train_test_splitにX、yを代入（デフォルト(指定なし)で訓練75%、検証25%となる）\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_iris, y_iris, random_state=42)\n",
    "\n",
    "# スクラッチしたクラスをインスタンス化し、ロジスティック回帰による分析を行う\n",
    "slr = ScratchLogisticRegression(num_iter=100, lr=0.0000000001, penalty=5, bias=False, verbose=False)\n",
    "slr.fit(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# rec = slr.predict(X_test, y_test)\n",
    "\n",
    "# 学習率をグラフ化\n",
    "plt.plot(np.arange(1,len(slr.loss)+1),slr.loss,label='train_loss',linewidth=5)\n",
    "plt.plot(np.arange(1,len(slr.val_loss)+1),slr.val_loss,label='val_loss',linewidth=5)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# # 可視化\n",
    "decision_region(X_test, y_test, slr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2134560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef639c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "X = np.array([1,2,3]).reshape(1,3)\n",
    "print(X[:,1:])\n",
    "print(np.e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fad33bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 12345678 \\\n",
    "    + 11111111\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e274ea15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2dc1612",
   "metadata": {},
   "source": [
    "### 【問題1】ラグランジュの未定乗数法による最急降下\n",
    "SVMの学習は、ラグランジュの未定乗数法を用います。<br>\n",
    "サンプル数分のラグランジュ乗数 $\\lambda$ を用意して、以下の式により更新していきます。この計算を行うメソッドをScratchSVMClassifierクラスに実装してください。<br>\n",
    "<br>\n",
    "　　　　$ \\lambda_i^{new} = \\lambda_i + \\alpha(1 - \\displaystyle\\sum_{j=1}^{n}\\lambda_j y_i y_j k(x_i, x_j)) $ <br>\n",
    "<br>\n",
    "ここで $k(x_i, x_j)$ はカーネル関数です。線形カーネルの場合は次のようになります。他のカーネル関数にも対応できるように、この部分は独立したメソッドとしておきましょう。<br>\n",
    "<br>\n",
    "　　　　$ k(x_i, x_j) = x_i^T x_j $ <br>\n",
    "<br>\n",
    "条件として、更新毎に $\\lambda_i >= 0$を満たす必要があります。満たさない場合は $\\lambda_i = 0$とします。<br>\n",
    "　　　　$i, j$ : サンプルのインデックス<br>\n",
    "　　　　$\\lambda_i^{new}$ : 更新後のi番目のサンプルのラグランジュ乗数<br>\n",
    "　　　　$\\lambda_i$ : 更新前のi番目のサンプルのラグランジュ乗数<br>\n",
    "　　　　$\\alpha$ : 学習率<br>\n",
    "　　　　$\\lambda_j$ : j番目のサンプルのラグランジュ乗数<br>\n",
    "　　　　$y_i$ : i番目のサンプルのラベル<br>\n",
    "　　　　$y_j$ : j番目のサンプルのラベル<br>\n",
    "　　　　$x_i$ : i番目のサンプルの特徴量ベクトル<br>\n",
    "　　　　$x_j$ : j番目のサンプルの特徴量ベクトル<br>\n",
    "<br>\n",
    "あるサンプルに対してのすべてのサンプルとの関係を計算していくことになります。<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7142dd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n",
      "(3,)\n",
      "[[-0.0755686]]\n",
      "[[-0.0755686]]\n",
      "[[-0.04246515]]\n",
      "[1.6243821  1.79075796 1.64522853]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class TEST_CLASS():\n",
    "    def __init__(self, num_iter, lr, kernel='linear', threshold=1e-5, verbose=False):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.kernel = kernel\n",
    "        self.threshold = threshold\n",
    "        self.verbose = verbose\n",
    "\n",
    "        # ランダム値を固定化\n",
    "        np.random.seed(0)\n",
    "\n",
    "    def lagrange_method(self, X, y):\n",
    "        # ラグランジュ乗数(X[0]分のベクトル)をランダムに設定\n",
    "        self.lagrange_multiplier = np.random.random(X.shape[0])\n",
    "\n",
    "        # ラグランジュの未定乗数法による最急降下\n",
    "        num = 0\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(X.shape[0]):\n",
    "                num += self.lagrange_multiplier[j]*y[i]*y[j]*kernel_function(X[i], X[j])\n",
    "            print(num)\n",
    "            lagrange_num = self.lagrange_multiplier[i] + self.lr * (1 - num)\n",
    "            if lagrange_num >= 0:\n",
    "                self.lagrange_multiplier[i] = lagrange_num\n",
    "            else:\n",
    "                self.lagrange_multiplier[i] = 0\n",
    "\n",
    "        print(self.lagrange_multiplier)\n",
    "\n",
    "\"\"\"\n",
    "    def lagrange_method(self, X, y):\n",
    "        # ラグランジュ乗数(X[0]分のベクトル)をランダムに設定\n",
    "        self.lagrange_multiplier = np.random.random(X.shape[0])\n",
    "\n",
    "        # ラグランジュの未定乗数法による最急降下\n",
    "        num = 0\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(X.shape[0]):\n",
    "                num += self.lagrange_multiplier[j]*y[i]*y[j]*kernel_function(X[i], X[j])\n",
    "\n",
    "        # ラグランジュ乗数の更新\n",
    "        for i in range(X.shape[0]):\n",
    "            print(self.lagrange_multiplier[i] + self.lr * (1 - num))\n",
    "            if (self.lagrange_multiplier[i] + self.lr * (1 - num)) >= 0:\n",
    "                self.lagrange_multiplier[i] = self.lagrange_multiplier[i] + self.lr * (1 - num)\n",
    "            else:\n",
    "                self.lagrange_multiplier[i] = 0\n",
    "\n",
    "        print(self.lagrange_multiplier)\n",
    "\"\"\"\n",
    "\n",
    "def kernel_function(vector_a, vector_b):\n",
    "\n",
    "    # 「線形カーネル」数の計算\n",
    "#     kernel_num = vector_a.T@vector_b\n",
    "    vector_c = vector_a.reshape(vector_a.shape[0],1)\n",
    "    vector_d = vector_b.reshape(vector_a.shape[0],1)\n",
    "    kernel_num = vector_c.T@vector_d\n",
    "\n",
    "    return kernel_num\n",
    "\n",
    "\n",
    "X = np.array([[0.1, 0.1, 0.1, 0.1],\n",
    "              [0.2, 0.2, 0.2, 0.2],\n",
    "              [0.3, 0.3, 0.3, 0.3]])\n",
    "y = np.array([0.1, 0.2, 0.3])\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "#################################################################\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# インスタンス化\n",
    "scaler = StandardScaler()\n",
    "# 訓練用のデータのみを.fitで標準化 ※説明変数のみ\n",
    "scaler.fit(X)\n",
    "# 訓練用、検証用双方のデータにtransformで標準化 ※説明変数のみ\n",
    "tr_X = scaler.transform(X)\n",
    "\n",
    "test = TEST_CLASS(num_iter=10, lr=1, kernel=\"linear\", threshold=1e-5, verbose=False)\n",
    "test.lagrange_method(tr_X, y)\n",
    "#################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41aed098",
   "metadata": {},
   "source": [
    "### 【問題2】サポートベクターの決定\n",
    "計算したラグランジュ乗数 $ \\lambda $ が設定した閾値より大きいサンプルをサポートベクターとして扱います。推定時にサポートベクターが必要になります。サポートベクターを決定し、インスタンス変数として保持しておくコードを書いてください。<br>\n",
    "\n",
    "閾値はハイパーパラメータですが、1e-5程度からはじめると良いでしょう。サポートベクターの数を出力させられるようにしておくと学習がうまく行えているかを確認できます。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2d85b6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.07556859745725636\n",
      "-0.07556859745725636\n",
      "-0.04246515262779371\n",
      "[1.6243821  1.79075796 1.64522853]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class TEST_CLASS():\n",
    "    def __init__(self, num_iter, lr, kernel='linear', threshold=1e-5, verbose=False):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.kernel = kernel\n",
    "        self.threshold = threshold # ←　これがサポートベクターの初期値になるが、サポートベクターではない\n",
    "        self.verbose = verbose\n",
    "\n",
    "        # サポートベクター数の初期値\n",
    "        self.support_bector_num = 2\n",
    "\n",
    "        # ランダム値を固定化\n",
    "        np.random.seed(0)\n",
    "\n",
    "    def lagrange_method(self, X, y):\n",
    "        # ラグランジュ乗数(X[0]分のベクトル)をランダムに設定\n",
    "        self.lagrange_multiplier = np.random.random(X.shape[0])\n",
    "\n",
    "        # ラグランジュの未定乗数法による最急降下\n",
    "        num = 0\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(X.shape[0]):\n",
    "                num += self.lagrange_multiplier[j]*y[i]*y[j]*kernel_function(X[i], X[j])\n",
    "            print(num)\n",
    "            lagrange_num = self.lagrange_multiplier[i] + self.lr * (1 - num)\n",
    "            if lagrange_num >= 0:\n",
    "                self.lagrange_multiplier[i] = lagrange_num\n",
    "            else:\n",
    "                self.lagrange_multiplier[i] = 0\n",
    "\n",
    "        print(self.lagrange_multiplier)\n",
    "\n",
    "        \"\"\"\n",
    "        self.n_support_vectors : int\n",
    "          サポートベクターの数\n",
    "        self.index_support_vectors : 次の形のndarray, shape (n_support_vectors,)\n",
    "          サポートベクターのインデックス\n",
    "        self.X_sv :  次の形のndarray, shape(n_support_vectors, n_features)\n",
    "          サポートベクターの特徴量\n",
    "        self.lam_sv :  次の形のndarray, shape(n_support_vectors, 1)\n",
    "          サポートベクターの未定乗数\n",
    "        self.y_sv :  次の形のndarray, shape(n_support_vectors, 1)\n",
    "          サポートベクターのラベル\n",
    "        \"\"\"\n",
    "\n",
    "        self.support_vector = []\n",
    "        self.n_support_vectors = 0\n",
    "        # サポートベクターの更新\n",
    "        for i in range(self.lagrange_multiplier.shape[0]):\n",
    "            # 初期値より大きいか→更新した値より大きいか\n",
    "            if self.lagrange_multiplier[i] > self.threshold:\n",
    "                self.support_vector.append(self.lagrange_multiplier[i])\n",
    "                self.n_support_vectors += 1\n",
    "#         print(self.support_vector)\n",
    "\n",
    "\n",
    "def kernel_function(vector_a, vector_b):\n",
    "\n",
    "    # 「線形カーネル」数の計算\n",
    "    kernel_num = vector_a.T@vector_b\n",
    "#     vector_c = vector_a.reshape(vector_a.shape[0],1)\n",
    "#     vector_d = vector_b.reshape(vector_a.shape[0],1)\n",
    "#     kernel_num = vector_c.T@vector_d\n",
    "\n",
    "#     print(kernel_num)\n",
    "\n",
    "    return kernel_num\n",
    "\n",
    "\n",
    "X = np.array([[0.1, 0.1, 0.1, 0.1],\n",
    "              [0.2, 0.2, 0.2, 0.2],\n",
    "              [0.3, 0.3, 0.3, 0.3]])\n",
    "y = np.array([0.1, 0.2, 0.3])\n",
    "\n",
    "#################################################################\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# インスタンス化\n",
    "scaler = StandardScaler()\n",
    "# 訓練用のデータのみを.fitで標準化 ※説明変数のみ\n",
    "scaler.fit(X)\n",
    "# 訓練用、検証用双方のデータにtransformで標準化 ※説明変数のみ\n",
    "tr_X = scaler.transform(X)\n",
    "\n",
    "test = TEST_CLASS(num_iter=10, lr=1, kernel=\"linear\", threshold=1e-5, verbose=False)\n",
    "test.lagrange_method(tr_X, y)\n",
    "#################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae61328",
   "metadata": {},
   "source": [
    "### 推定\n",
    "推定時には、推定したいデータの特徴量とサポートベクターの特徴量をカーネル関数によって計算します。求めた $f(x)$ の符号が分類結果です。<br>\n",
    "<br>\n",
    "　　　　$ f(x) = \\displaystyle\\sum_{n=1}^{N}\\lambda_n y_{sv\\_n} k(x, s_n) $ <br>\n",
    "<br>\n",
    "　　　　$x$ : 推定したいデータの特徴量ベクトル<br>\n",
    "　　　　$N$ : サポートベクターの数<br>\n",
    "　　　　$n$ : サポートベクターのインデックス<br>\n",
    "　　　　$\\lambda_n$ : $n$番目のサポートベクターのラグランジュ乗数<br>\n",
    "　　　　$y_{sv_n}$ : $n$番目のサポートベクターのラベル<br>\n",
    "　　　　$k()$ : カーネル関数<br>\n",
    "　　　　$s_n$ : $n$番目のサポートベクターの特徴量<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ac84da6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.6243821  1.79075796 1.64522853]\n",
      "[-8.40044053e-09 -8.33931013e-09 -8.38061808e-09]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class TEST_CLASS():\n",
    "    def __init__(self, num_iter, lr, kernel='linear', threshold=1e-5, verbose=False):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.kernel = kernel\n",
    "        self.threshold = threshold # ←　これがサポートベクターの初期値になるが、サポートベクターではない\n",
    "        self.verbose = verbose\n",
    "\n",
    "        # ランダム値を固定化\n",
    "        np.random.seed(0)\n",
    "\n",
    "    def lagrange_method(self, X, y):\n",
    "        # ラグランジュ乗数(X[0]分のベクトル)をランダムに設定\n",
    "        self.lagrange_multiplier = np.random.random(X.shape[0])\n",
    "\n",
    "        # ラグランジュの未定乗数法による最急降下\n",
    "        num = 0\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(X.shape[0]):\n",
    "                num += self.lagrange_multiplier[j]*y[i]*y[j]*kernel_function(X[i], X[j])\n",
    "            lagrange_num = self.lagrange_multiplier[i] + self.lr * (1 - num)\n",
    "            if lagrange_num >= 0:\n",
    "                self.lagrange_multiplier[i] = lagrange_num\n",
    "            else:\n",
    "                self.lagrange_multiplier[i] = 0\n",
    "\n",
    "        print(self.lagrange_multiplier)\n",
    "\n",
    "        \"\"\"\n",
    "        self.n_support_vectors : int\n",
    "          サポートベクターの数\n",
    "        self.index_support_vectors : 次の形のndarray, shape (n_support_vectors,)\n",
    "          サポートベクターのインデックス\n",
    "        self.X_sv :  次の形のndarray, shape(n_support_vectors, n_features)\n",
    "          サポートベクターの特徴量\n",
    "        self.lam_sv :  次の形のndarray, shape(n_support_vectors, 1)\n",
    "          サポートベクターの未定乗数\n",
    "        self.y_sv :  次の形のndarray, shape(n_support_vectors, 1)\n",
    "          サポートベクターのラベル\n",
    "        \"\"\"\n",
    "        # サポートベクター用の変数\n",
    "        self.support_vector = []\n",
    "        self.n_support_vectors = 0\n",
    "\n",
    "        # サポートベクターの更新\n",
    "        for i in range(self.lagrange_multiplier.shape[0]):\n",
    "            # 初期値より大きいか→更新した値より大きいか\n",
    "            if self.lagrange_multiplier[i] > self.threshold:\n",
    "                self.support_vector.append(self.lagrange_multiplier[i])\n",
    "                self.n_support_vectors += 1\n",
    "#         print(self.support_vector)\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        SVM分類器を使いラベルを推定する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            SVM分類器による推定結果\n",
    "        \"\"\"\n",
    "\n",
    "        for i in range(len(self.support_vector)):\n",
    "            print(self.support_vector)\n",
    "            y_pred = self.lagrange_multiplier * self.support_vector[i] * kernel_function(X[i], self.support_vector)\n",
    "\n",
    "        print(type(y_pred))\n",
    "        print(y_pred.shape)\n",
    "        print(y_pred)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "\n",
    "def kernel_function(vector_a, vector_b):\n",
    "\n",
    "    # 「線形カーネル」数の計算\n",
    "    kernel_num = vector_a.T@vector_b\n",
    "#     vector_c = vector_a.reshape(vector_a.shape[0],1)\n",
    "#     vector_d = vector_b.reshape(vector_a.shape[0],1)\n",
    "#     kernel_num = vector_c.T@vector_d\n",
    "\n",
    "#     print(kernel_num)\n",
    "\n",
    "    return kernel_num\n",
    "\n",
    "\n",
    "X = np.array([[0.1, 0.1, 0.1, 0.1],\n",
    "              [0.2, 0.2, 0.2, 0.2],\n",
    "              [0.3, 0.3, 0.3, 0.3]])\n",
    "y = np.array([0.1, 0.2, 0.3])\n",
    "\n",
    "#################################################################\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# インスタンス化\n",
    "scaler = StandardScaler()\n",
    "# 訓練用のデータのみを.fitで標準化 ※説明変数のみ\n",
    "scaler.fit(X)\n",
    "# 訓練用、検証用双方のデータにtransformで標準化 ※説明変数のみ\n",
    "tr_X = scaler.transform(X)\n",
    "\n",
    "test = TEST_CLASS(num_iter=10, lr=1, kernel=\"linear\", threshold=1e-5, verbose=False)\n",
    "test.lagrange_method(tr_X, y)\n",
    "#################################################################\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccb05ca",
   "metadata": {},
   "source": [
    "### 【問題4】学習と推定\n",
    "機械学習スクラッチ入門のSprintで用意したシンプルデータセット1の2値分類に対してスクラッチ実装の学習と推定を行なってください。<br>\n",
    "scikit-learnによる実装と比べ、正しく動いているかを確認してください。<br>\n",
    "AccuracyやPrecision、Recallなどの指標値はscikit-learnを使用してください。<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a80864bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.541422   0.69140743]\n",
      "(125, 2)\n",
      "[[ 0.02897535 -0.50874319]\n",
      " [-0.22551893  0.21472375]\n",
      " [-0.50189059 -0.00095473]\n",
      " [-0.0927355   0.572386  ]\n",
      " [-0.69820643 -0.11865917]\n",
      " [-0.44684731  0.13330007]\n",
      " [ 0.62999164  0.13867023]\n",
      " [ 0.28681071 -0.16051768]\n",
      " [ 0.24793418 -0.3268908 ]\n",
      " [ 0.18088032 -0.42985063]\n",
      " [ 0.26773774 -0.26308628]\n",
      " [-0.48286654  0.13420233]\n",
      " [-0.76246994 -0.02234087]\n",
      " [ 0.19828022 -0.20632102]\n",
      " [-0.29235032  0.16941303]\n",
      " [-0.3442554   0.36466015]\n",
      " [-0.24479423  0.2541364 ]\n",
      " [ 0.07855038 -0.25242128]\n",
      " [ 0.57210522 -0.01141071]\n",
      " [-0.30689091  0.1436069 ]\n",
      " [-0.35097084  0.27039786]\n",
      " [-0.11863542  0.37482576]\n",
      " [ 0.04541255 -0.53983888]\n",
      " [ 0.10659961 -0.2509027 ]\n",
      " [-0.46448501  0.19567843]\n",
      " [ 0.34375895 -0.4565499 ]\n",
      " [-0.412818    0.1121564 ]\n",
      " [ 0.62807909 -0.11502637]\n",
      " [-0.30120375  0.36822663]\n",
      " [ 0.29094554 -0.28537883]\n",
      " [-0.03344865  0.35952556]\n",
      " [-0.38779241  0.26095052]\n",
      " [-0.39566437  0.29573372]\n",
      " [ 0.28725548 -0.23290383]\n",
      " [-0.00960003  0.60250027]\n",
      " [-0.11564026  0.40841245]\n",
      " [-0.34264425  0.2616929 ]\n",
      " [-0.21500986  0.32507771]\n",
      " [ 0.28307112 -0.27839165]\n",
      " [ 0.42782458 -0.31295996]\n",
      " [-0.44415414  0.18241488]\n",
      " [ 0.28680164 -0.28092837]\n",
      " [ 0.17197308 -0.34551334]\n",
      " [-0.30724349  0.31702197]\n",
      " [ 0.36576831 -0.25863161]\n",
      " [ 0.15636797 -0.27621531]\n",
      " [-0.41440321  0.0892692 ]\n",
      " [ 0.0298766   0.62194421]\n",
      " [-0.48249458 -0.00423571]\n",
      " [ 0.39800997 -0.08514143]\n",
      " [ 0.55026911  0.00634554]\n",
      " [-0.06356235  0.55928526]\n",
      " [-0.00345396  0.54286374]\n",
      " [ 0.08695386  0.59375642]\n",
      " [-0.36818023  0.28320699]\n",
      " [ 0.07264195 -0.25362727]\n",
      " [-0.28383133  0.30338716]\n",
      " [-0.18749527  0.25663882]\n",
      " [-0.48030039  0.33343569]\n",
      " [ 0.29602286 -0.10525564]\n",
      " [ 0.35214557 -0.28164446]\n",
      " [-0.02392492  0.59212894]\n",
      " [-0.18538458  0.33843654]\n",
      " [-0.18413056  0.30391457]\n",
      " [ 0.33903606 -0.0413491 ]\n",
      " [-0.39961381  0.21125409]\n",
      " [ 0.3640574  -0.1481648 ]\n",
      " [ 0.59318458 -0.0463381 ]\n",
      " [ 0.40710031 -0.12362424]\n",
      " [ 0.35086106 -0.17848576]\n",
      " [ 0.33265058 -0.07278259]\n",
      " [-0.21049959  0.17298621]\n",
      " [ 0.41082593 -0.09437683]\n",
      " [-0.06126344  0.45219697]\n",
      " [-0.07109696  0.33166402]\n",
      " [-0.4999551   0.2310543 ]\n",
      " [ 0.58450316 -0.09221772]\n",
      " [ 0.44065435 -0.16169306]\n",
      " [-0.05743074  0.58505656]\n",
      " [-0.0590383   0.42850967]\n",
      " [-0.17414281  0.52193356]\n",
      " [-0.2298446   0.39354366]\n",
      " [-0.48625906  0.18920712]\n",
      " [-0.08173112 -0.75340797]\n",
      " [-0.3884595   0.16420727]\n",
      " [ 0.10965995 -0.48177661]\n",
      " [ 0.36379657 -0.05121245]\n",
      " [-0.41453755  0.14592897]\n",
      " [-0.35292272  0.29214936]\n",
      " [ 0.21904832 -0.50267944]\n",
      " [ 0.56233507  0.0610185 ]\n",
      " [-0.15643705  0.40468719]\n",
      " [ 0.11150724  0.75570151]\n",
      " [ 0.08873341 -0.34638256]\n",
      " [-0.48606073  0.1335245 ]\n",
      " [-0.61684205 -0.20206041]\n",
      " [-0.24432434  0.2856395 ]\n",
      " [ 0.17123051 -0.36058093]\n",
      " [-0.67133018  0.11129016]\n",
      " [ 0.21413196 -0.18455107]\n",
      " [-0.03993412 -0.31802011]\n",
      " [ 0.38171211 -0.24708077]\n",
      " [-0.77357832 -0.19622282]\n",
      " [ 0.31385561 -0.14316475]\n",
      " [-0.22098938  0.26081761]\n",
      " [-0.12617643  0.35316668]\n",
      " [ 0.25720046 -0.22648462]\n",
      " [ 0.4970516  -0.18403611]\n",
      " [-0.30631041  0.17179064]\n",
      " [ 0.33439853 -0.31173559]\n",
      " [ 0.25702499 -0.3660502 ]\n",
      " [ 0.13930404 -0.34002061]\n",
      " [-0.14396385  0.43567666]\n",
      " [ 0.4447737  -0.19192824]\n",
      " [-0.64611899 -0.18519674]\n",
      " [ 0.15621707 -0.33628491]\n",
      " [ 0.34767581 -0.28380032]\n",
      " [-0.7284754   0.02763061]\n",
      " [-0.25305733  0.39439251]\n",
      " [-0.44743097  0.1411598 ]\n",
      " [-0.25350517  0.2369799 ]\n",
      " [-0.30656696 -0.04635599]\n",
      " [ 0.36239971 -0.26721034]\n",
      " [-0.29729825 -0.02755414]\n",
      " [-0.01746064  0.60582311]]\n",
      "[[ 0.02897535 -0.50874319]\n",
      " [-0.22551893  0.21472375]\n",
      " [-0.50189059 -0.00095473]\n",
      " [-0.0927355   0.572386  ]\n",
      " [-0.69820643 -0.11865917]\n",
      " [-0.44684731  0.13330007]\n",
      " [ 0.62999164  0.13867023]\n",
      " [ 0.28681071 -0.16051768]\n",
      " [ 0.24793418 -0.3268908 ]\n",
      " [ 0.18088032 -0.42985063]\n",
      " [ 0.26773774 -0.26308628]\n",
      " [-0.48286654  0.13420233]\n",
      " [-0.76246994 -0.02234087]\n",
      " [ 0.19828022 -0.20632102]\n",
      " [-0.29235032  0.16941303]\n",
      " [-0.3442554   0.36466015]\n",
      " [-0.24479423  0.2541364 ]\n",
      " [ 0.07855038 -0.25242128]\n",
      " [ 0.57210522 -0.01141071]\n",
      " [-0.30689091  0.1436069 ]\n",
      " [-0.35097084  0.27039786]\n",
      " [-0.11863542  0.37482576]\n",
      " [ 0.04541255 -0.53983888]\n",
      " [ 0.10659961 -0.2509027 ]\n",
      " [-0.46448501  0.19567843]\n",
      " [ 0.34375895 -0.4565499 ]\n",
      " [-0.412818    0.1121564 ]\n",
      " [ 0.62807909 -0.11502637]\n",
      " [-0.30120375  0.36822663]\n",
      " [ 0.29094554 -0.28537883]\n",
      " [-0.03344865  0.35952556]\n",
      " [-0.38779241  0.26095052]\n",
      " [-0.39566437  0.29573372]\n",
      " [ 0.28725548 -0.23290383]\n",
      " [-0.00960003  0.60250027]\n",
      " [-0.11564026  0.40841245]\n",
      " [-0.34264425  0.2616929 ]\n",
      " [-0.21500986  0.32507771]\n",
      " [ 0.28307112 -0.27839165]\n",
      " [ 0.42782458 -0.31295996]\n",
      " [-0.44415414  0.18241488]\n",
      " [ 0.28680164 -0.28092837]\n",
      " [ 0.17197308 -0.34551334]\n",
      " [-0.30724349  0.31702197]\n",
      " [ 0.36576831 -0.25863161]\n",
      " [ 0.15636797 -0.27621531]\n",
      " [-0.41440321  0.0892692 ]\n",
      " [ 0.0298766   0.62194421]\n",
      " [-0.48249458 -0.00423571]\n",
      " [ 0.39800997 -0.08514143]\n",
      " [ 0.55026911  0.00634554]\n",
      " [-0.06356235  0.55928526]\n",
      " [-0.00345396  0.54286374]\n",
      " [ 0.08695386  0.59375642]\n",
      " [-0.36818023  0.28320699]\n",
      " [ 0.07264195 -0.25362727]\n",
      " [-0.28383133  0.30338716]\n",
      " [-0.18749527  0.25663882]\n",
      " [-0.48030039  0.33343569]\n",
      " [ 0.29602286 -0.10525564]\n",
      " [ 0.35214557 -0.28164446]\n",
      " [-0.02392492  0.59212894]\n",
      " [-0.18538458  0.33843654]\n",
      " [-0.18413056  0.30391457]\n",
      " [ 0.33903606 -0.0413491 ]\n",
      " [-0.39961381  0.21125409]\n",
      " [ 0.3640574  -0.1481648 ]\n",
      " [ 0.59318458 -0.0463381 ]\n",
      " [ 0.40710031 -0.12362424]\n",
      " [ 0.35086106 -0.17848576]\n",
      " [ 0.33265058 -0.07278259]\n",
      " [-0.21049959  0.17298621]\n",
      " [ 0.41082593 -0.09437683]\n",
      " [-0.06126344  0.45219697]\n",
      " [-0.07109696  0.33166402]\n",
      " [-0.4999551   0.2310543 ]\n",
      " [ 0.58450316 -0.09221772]\n",
      " [ 0.44065435 -0.16169306]\n",
      " [-0.05743074  0.58505656]\n",
      " [-0.0590383   0.42850967]\n",
      " [-0.17414281  0.52193356]\n",
      " [-0.2298446   0.39354366]\n",
      " [-0.48625906  0.18920712]\n",
      " [-0.08173112 -0.75340797]\n",
      " [-0.3884595   0.16420727]\n",
      " [ 0.10965995 -0.48177661]\n",
      " [ 0.36379657 -0.05121245]\n",
      " [-0.41453755  0.14592897]\n",
      " [-0.35292272  0.29214936]\n",
      " [ 0.21904832 -0.50267944]\n",
      " [ 0.56233507  0.0610185 ]\n",
      " [-0.15643705  0.40468719]\n",
      " [ 0.11150724  0.75570151]\n",
      " [ 0.08873341 -0.34638256]\n",
      " [-0.48606073  0.1335245 ]\n",
      " [-0.61684205 -0.20206041]\n",
      " [-0.24432434  0.2856395 ]\n",
      " [ 0.17123051 -0.36058093]\n",
      " [-0.67133018  0.11129016]\n",
      " [ 0.21413196 -0.18455107]\n",
      " [-0.03993412 -0.31802011]\n",
      " [ 0.38171211 -0.24708077]\n",
      " [-0.77357832 -0.19622282]\n",
      " [ 0.31385561 -0.14316475]\n",
      " [-0.22098938  0.26081761]\n",
      " [-0.12617643  0.35316668]\n",
      " [ 0.25720046 -0.22648462]\n",
      " [ 0.4970516  -0.18403611]\n",
      " [-0.30631041  0.17179064]\n",
      " [ 0.33439853 -0.31173559]\n",
      " [ 0.25702499 -0.3660502 ]\n",
      " [ 0.13930404 -0.34002061]\n",
      " [-0.14396385  0.43567666]\n",
      " [ 0.4447737  -0.19192824]\n",
      " [-0.64611899 -0.18519674]\n",
      " [ 0.15621707 -0.33628491]\n",
      " [ 0.34767581 -0.28380032]\n",
      " [-0.7284754   0.02763061]\n",
      " [-0.25305733  0.39439251]\n",
      " [-0.44743097  0.1411598 ]\n",
      " [-0.25350517  0.2369799 ]\n",
      " [-0.30656696 -0.04635599]\n",
      " [ 0.36239971 -0.26721034]\n",
      " [-0.29729825 -0.02755414]\n",
      " [-0.01746064  0.60582311]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class ScratchSVMClassifier():\n",
    "    \"\"\"\n",
    "    SVM分類器のスクラッチ実装\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_iter : int\n",
    "      イテレーション数\n",
    "    lr : float\n",
    "      学習率\n",
    "    kernel : str\n",
    "      カーネルの種類。線形カーネル（linear）か多項式カーネル（polly）\n",
    "    threshold : float\n",
    "      サポートベクターを選ぶための閾値\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.n_support_vectors : int\n",
    "      サポートベクターの数\n",
    "    self.index_support_vectors : 次の形のndarray, shape (n_support_vectors,)\n",
    "      サポートベクターのインデックス\n",
    "    self.X_sv :  次の形のndarray, shape(n_support_vectors, n_features)\n",
    "      サポートベクターの特徴量\n",
    "    self.lam_sv :  次の形のndarray, shape(n_support_vectors, 1)\n",
    "      サポートベクターの未定乗数\n",
    "    self.y_sv :  次の形のndarray, shape(n_support_vectors, 1)\n",
    "      サポートベクターのラベル\n",
    "    \"\"\"\n",
    "    def __init__(self, num_iter, lr, kernel='linear', threshold=1e-5, verbose=False):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.kernel = kernel\n",
    "        self.threshold = threshold\n",
    "        self.verbose = verbose\n",
    "\n",
    "        # ランダム値を固定化\n",
    "        np.random.seed(0)\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        SVM分類器を学習する。検証データが入力された場合はそれに対する精度もイテレーションごとに計算する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        # ラグランジュ乗数(X[0]分のベクトル)をランダムに設定\n",
    "        self.lagrange_multiplier = np.random.random(X.shape[1])\n",
    "\n",
    "        for _roop_iter in range(self.iter):\n",
    "            # ラグランジュの未定乗数法による最急降下\n",
    "            num = 0\n",
    "            for i in range(X.shape[1]):\n",
    "                for j in range(X.shape[1]):\n",
    "                    num += self.lagrange_multiplier[j]*y[i]*y[j]*kernel_function(X[:,i], X[:,j])\n",
    "                lagrange_num = self.lagrange_multiplier[i] + self.lr * (1 - num)\n",
    "                if lagrange_num >= 0:\n",
    "                    self.lagrange_multiplier[i] = lagrange_num\n",
    "                else:\n",
    "                    self.lagrange_multiplier[i] = 0\n",
    "\n",
    "#             print(self.lagrange_multiplier)\n",
    "\n",
    "            # サポートベクター用の変数\n",
    "            self.support_vector = []\n",
    "            self.n_support_vectors = 0\n",
    "            # サポートベクターの更新\n",
    "            for i in range(self.lagrange_multiplier.shape[0]):\n",
    "                # 初期値より大きいか→更新した値より大きいか\n",
    "                if self.lagrange_multiplier[i] > self.threshold:\n",
    "                    self.support_vector.append(self.lagrange_multiplier[i])\n",
    "                    self.n_support_vectors += 1\n",
    "            self.support_vector = np.array(self.support_vector)\n",
    "        print(self.support_vector)\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        SVM分類器を使いラベルを推定する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            SVM分類器による推定結果\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        for i in range(self.n_support_vectors):\n",
    "#             print(self.n_support_vectors)\n",
    "#             print(X.shape) # 2\n",
    "#             print(self.support_vector[i].shape) # 39\n",
    "            y_pred = self.lagrange_multiplier[i] * self.support_vector[i] * kernel_function(X, self.support_vector[i])\n",
    "        print(y_pred.shape)\n",
    "        print(y_pred)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "\n",
    "def kernel_function(vector_a, vector_b):\n",
    "\n",
    "    # 「線形カーネル」数の計算\n",
    "    kernel_num = np.dot(vector_a,vector_b)\n",
    "#     kernel_num = vector_a.T@vector_b\n",
    "#     vector_c = vector_a.reshape(vector_a.shape[0],1)\n",
    "#     vector_d = vector_b.reshape(vector_a.shape[0],1)\n",
    "#     kernel_num = vector_c.T@vector_d\n",
    "\n",
    "#     print(kernel_num)\n",
    "\n",
    "    return kernel_num\n",
    "\n",
    "\n",
    "\n",
    "# シンプルデータセット1 作成コード\n",
    "np.random.seed(seed=0)\n",
    "n_samples = 500\n",
    "f0 = [-1, 2]\n",
    "f1 = [2, -1]\n",
    "cov = [[1.0,0.8], [0.8, 1.0]]\n",
    "f0 = np.random.multivariate_normal(f0, cov, n_samples // 2)\n",
    "f1 = np.random.multivariate_normal(f1, cov, n_samples // 2)\n",
    "X = np.concatenate([f0, f1])\n",
    "y = np.concatenate([\n",
    "    np.full(n_samples // 2, 1),\n",
    "    np.full(n_samples // 2, -1)\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "tr_X_train = scaler.transform(X_train)\n",
    "tr_X_test = scaler.transform(X_test)\n",
    "\n",
    "s_svmc = ScratchSVMClassifier(num_iter=10, lr=0.00001, kernel=\"linear\", threshold=1e-5, verbose=False)\n",
    "s_svmc.fit(tr_X_train, y)\n",
    "y_pred = s_svmc.predict(tr_X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6ed47689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 2)\n",
      "(25,)\n",
      "(206568, 2)\n",
      "[[-0.87647323 -0.85280101]\n",
      " [-0.87316799 -0.85280101]\n",
      " [-0.86986276 -0.85280101]\n",
      " ...\n",
      " [ 0.62079747  0.64116445]\n",
      " [ 0.62410271  0.64116445]\n",
      " [ 0.62740794  0.64116445]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 413136 into shape (453,456)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-3b2fdcd9b01f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_X_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m \u001b[0mdecision_region\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_X_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms_svmc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'SVM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'xlabel'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mylabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ylabel'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'0'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-102-3b2fdcd9b01f>\u001b[0m in \u001b[0;36mdecision_region\u001b[1;34m(X, y, model, step, title, xlabel, ylabel, target_names)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mmesh_f0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmesh_f1\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeshgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mmesh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmesh_f0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmesh_f1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmesh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmesh_f0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;31m# plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 413136 into shape (453,456)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "\n",
    "def decision_region(X, y, model, step=0.01, title='decision region', xlabel='xlabel', ylabel='ylabel', target_names=['versicolor', 'virginica']):\n",
    "    \"\"\"\n",
    "    2値分類を2次元の特徴量で学習したモデルの決定領域を描く。\n",
    "    背景の色が学習したモデルによる推定値から描画される。\n",
    "    散布図の点は訓練データまたは検証データである。\n",
    "\n",
    "    Parameters\n",
    "    ----------------\n",
    "    X : ndarray, shape(n_samples, 2)\n",
    "        特徴量\n",
    "    y : ndarray, shape(n_samples,)\n",
    "        ラベル\n",
    "    model : object\n",
    "        学習したモデルのインスンタスを入れる\n",
    "    step : float, (default : 0.1)\n",
    "        推定値を計算する間隔を設定する\n",
    "    title : str\n",
    "        グラフのタイトルの文章を与える\n",
    "    xlabel, ylabel : str\n",
    "        軸ラベルの文章を与える\n",
    "    target_names= : list of str\n",
    "        凡例の一覧を与える\n",
    "    \"\"\"\n",
    "    # setting\n",
    "    scatter_color = ['red', 'blue']\n",
    "    contourf_color = ['pink', 'skyblue']\n",
    "    n_class = 2\n",
    "    mesh_f0, mesh_f1  = np.meshgrid(np.arange(np.min(X[:,0])-0.5, np.max(X[:,0])+0.5, step), np.arange(np.min(X[:,1])-0.5, np.max(X[:,1])+0.5, step))\n",
    "    mesh = np.c_[np.ravel(mesh_f0),np.ravel(mesh_f1)]\n",
    "    y_pred = model.predict(mesh).reshape(mesh_f0.shape)\n",
    "\n",
    "    # plot\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.contourf(mesh_f0, mesh_f1, y_pred, n_class-1, cmap=ListedColormap(contourf_color))\n",
    "    plt.contour(mesh_f0, mesh_f1, y_pred, n_class-1, colors='y', linewidths=3, alpha=0.5)\n",
    "    for i, target in enumerate(set(y)):\n",
    "        plt.scatter(X[y==target][:, 0], X[y==target][:, 1], s=80, color=scatter_color[i], label=target_names[i], marker='o')\n",
    "    patches = [mpatches.Patch(color=scatter_color[i], label=target_names[i]) for i in range(n_class)]\n",
    "    plt.legend(handles=patches)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# シンプルデータセット1 作成コード\n",
    "np.random.seed(seed=0)\n",
    "n_samples = 500\n",
    "f0 = [-1, 2]\n",
    "f1 = [2, -1]\n",
    "cov = [[1.0,0.8], [0.8, 1.0]]\n",
    "f0 = np.random.multivariate_normal(f0, cov, n_samples // 2)\n",
    "f1 = np.random.multivariate_normal(f1, cov, n_samples // 2)\n",
    "X = np.concatenate([f0, f1])\n",
    "y = np.concatenate([\n",
    "    np.full(n_samples // 2, 1),\n",
    "    np.full(n_samples // 2, -1)\n",
    "])\n",
    "\n",
    "\n",
    "X = X[:100,:]\n",
    "y = y[:100]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "tr_X_train = scaler.transform(X_train)\n",
    "tr_X_test = scaler.transform(X_test)\n",
    "print(tr_X_test.shape)\n",
    "print(y_test.shape)\n",
    "decision_region(tr_X_test, y_test, s_svmc, step=0.01, title='SVM', xlabel='xlabel', ylabel='ylabel', target_names=['0','1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785a8bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8658c8da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

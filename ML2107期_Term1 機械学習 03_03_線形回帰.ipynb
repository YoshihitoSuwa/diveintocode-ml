{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7da90d29",
   "metadata": {},
   "source": [
    "# 線形回帰\n",
    "## １．このSprintについて\n",
    "### Sprintの目的\n",
    "　・スクラッチを通して線形回帰を理解する<br>\n",
    "　・オブジェクト指向を意識した実装に慣れる<br>\n",
    "　・数式をコードに落とし込めるようにする<br>\n",
    "\n",
    "### どのように学ぶか\n",
    "　スクラッチで線形回帰を実装した後、学習と検証を行っていきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7304860e",
   "metadata": {},
   "source": [
    "## ２．線形回帰スクラッチ\n",
    "　線形回帰のクラスをスクラッチで作成していきます。NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。<br>\n",
    "　以下に雛形を用意してあります。このScratchLinearRegressionクラスにコードを書き加えていってください。<br>\n",
    "<br>\n",
    "　<b>雛形</b>\n",
    "```\n",
    "class ScratchLinearRegression():\n",
    "    \"\"\"\n",
    "    線形回帰のスクラッチ実装\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    num_iter : int\n",
    "      イテレーション数\n",
    "    lr : float\n",
    "      学習率\n",
    "    no_bias : bool\n",
    "      バイアス項を入れない場合はTrue\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    self.coef_ : 次の形のndarray, shape (n_features,)\n",
    "      パラメータ\n",
    "    self.loss : 次の形のndarray, shape (self.iter,)\n",
    "      訓練データに対する損失の記録\n",
    "    self.val_loss : 次の形のndarray, shape (self.iter,)\n",
    "      検証データに対する損失の記録\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_iter, lr, no_bias, verbose):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.no_bias = no_bias\n",
    "        self.verbose = verbose\n",
    "        # 損失を記録する配列を用意\n",
    "        self.loss = np.zeros(self.iter)\n",
    "        self.val_loss = np.zeros(self.iter)\n",
    "        \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        線形回帰を学習する。検証データが入力された場合はそれに対する損失と精度もイテレーションごとに計算する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程を出力\n",
    "            print()\n",
    "        pass\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        線形回帰を使い推定する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            線形回帰による推定結果\n",
    "        \"\"\"\n",
    "        pass\n",
    "        return\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c14313",
   "metadata": {},
   "source": [
    "### 【問題1】仮定関数\n",
    "　以下の数式で表される線形回帰の仮定関数を実装してください。メソッドの雛形を用意してあります。<br>\n",
    "<br>\n",
    "　　　　$ h_{\\theta}(x) = \\theta_0x_0 + \\theta_1x_1 + ... + \\theta_jx_j + ... + \\theta_nx_n. (x_0 = 1)$<br>\n",
    "<br>\n",
    "　　$ x $ : 特徴量ベクトル<br>\n",
    "　　$ \\theta $ : パラメータベクトル<br>\n",
    "　　$ n $ : 特徴量の数<br>\n",
    "　　$ x_j $ : j番目の特徴量<br>\n",
    "　　$ \\theta_j $ : j番目のパラメータ(重み)<br>\n",
    "<br>\n",
    "　特徴量の数$ n $は任意の値に対応できる実装にしてください。<br>\n",
    "　なお、ベクトル形式で表すと以下のようになります。<br>\n",
    "<br>\n",
    "　　　　$ h_{\\theta}(x) = \\theta^T・x. $<br>\n",
    "<br>\n",
    "　<b>雛形</b><br>\n",
    "　クラスの外から呼び出すことがないメソッドのため、Pythonの慣例としてアンダースコアを先頭にひとつつけています。\n",
    "```\n",
    "def _linear_hypothesis(self, X):\n",
    "    \"\"\"\n",
    "    線形の仮定関数を計算する\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    Returns\n",
    "    -------\n",
    "      次の形のndarray, shape (n_samples, 1)\n",
    "      線形の仮定関数による推定結果\n",
    "    \"\"\"\n",
    "    pass\n",
    "    return\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac311bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# class ScratchLinearRegression():\n",
    "#     \"\"\"\n",
    "#     線形回帰のスクラッチ実装\n",
    "    \n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     num_iter : int\n",
    "#       イテレーション数\n",
    "#     lr : float\n",
    "#       学習率\n",
    "#     no_bias : bool\n",
    "#       バイアス項を入れない場合はTrue\n",
    "#     verbose : bool\n",
    "#       学習過程を出力する場合はTrue\n",
    "    \n",
    "#     Attributes\n",
    "#     ----------\n",
    "#     self.coef_ : 次の形のndarray, shape (n_features,)\n",
    "#       パラメータ\n",
    "#     self.loss : 次の形のndarray, shape (self.iter,)\n",
    "#       訓練データに対する損失の記録\n",
    "#     self.val_loss : 次の形のndarray, shape (self.iter,)\n",
    "#       検証データに対する損失の記録\n",
    "#     \"\"\"\n",
    "    \n",
    "#     def __init__(self, num_iter, lr, no_bias, verbose):\n",
    "#         # ハイパーパラメータを属性として記録\n",
    "#         self.iter = num_iter\n",
    "#         self.lr = lr\n",
    "#         self.no_bias = no_bias\n",
    "#         self.verbose = verbose\n",
    "\n",
    "#         # 損失を記録する配列を用意\n",
    "#         self.loss = np.zeros(self.iter)\n",
    "#         self.val_loss = np.zeros(self.iter)\n",
    "\n",
    "#     def fit(self, X, y, X_val=None, y_val=None):\n",
    "#         \"\"\"\n",
    "#         線形回帰を学習する。検証データが入力された場合はそれに対する損失と精度もイテレーションごとに計算する。\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         X : 次の形のndarray, shape (n_samples, n_features)\n",
    "#             訓練データの特徴量\n",
    "#         y : 次の形のndarray, shape (n_samples, )\n",
    "#             訓練データの正解値\n",
    "#         X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "#             検証データの特徴量\n",
    "#         y_val : 次の形のndarray, shape (n_samples, )\n",
    "#             検証データの正解値\n",
    "#         \"\"\"\n",
    "#         if self.verbose:\n",
    "#             #verboseをTrueにした際は学習過程を出力\n",
    "#             print()\n",
    "#         else:\n",
    "#             # メイン処理\n",
    "#             for i in range(学習回数):\n",
    "#             # 問題1（過程関数の計算）\n",
    "#             self._linear_hypothesis(X)\n",
    "\n",
    "#             # 問題2（最急降下法によるパラメータの更新値計算）\n",
    "#             self._gradient_descent(X, error)\n",
    "\n",
    "#             # 問題7（学習曲線のプロット）のグラフ描画時（問題5（損失関数）で作成した関数を使用）\n",
    "#             self._loss_func(・・・)\n",
    "\n",
    "#         pass\n",
    "\n",
    "#     def _linear_hypothesis(self, X):\n",
    "#         \"\"\"\n",
    "#         線形の仮定関数を計算する\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         X : 次の形のndarray, shape (n_samples, n_features)\n",
    "#           訓練データ\n",
    "#         Returns\n",
    "#         -------\n",
    "#         hypothetical_y : 次の形のndarray, shape (n_samples, 1)\n",
    "#           線形の仮定関数による推定結果\n",
    "#         \"\"\"\n",
    "\n",
    "#         # Xの1列目に「1」を埋める theta0の値のため\n",
    "#         zeroplus_X = np.array([[1, i] for i in X])\n",
    "\n",
    "#         # ランダムな値をtheta0, theta1の初期値に設定する\n",
    "#         theta = np.random.random(len(large_x[0]))\n",
    "\n",
    "#         # 転置行列積\n",
    "#         self.hypothetical_y = theta.T @ zeroplus_X.T\n",
    "\n",
    "#         return\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         \"\"\"\n",
    "#         線形回帰を使い推定する。\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         X : 次の形のndarray, shape (n_samples, n_features)\n",
    "#             サンプル\n",
    "#         Returns\n",
    "#         -------\n",
    "#             次の形のndarray, shape (n_samples, 1)\n",
    "#             線形回帰による推定結果\n",
    "#         \"\"\"\n",
    "#         pass\n",
    "#         return\n",
    "\n",
    "#     def _gradient_descent(self, X, error):\n",
    "#         \"\"\"\n",
    "#         説明を記述\n",
    "#         \"\"\"\n",
    "#         pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b96730",
   "metadata": {},
   "source": [
    "### 【問題2】最急降下法\n",
    "　最急降下法により学習させる実装を行なってください。<br>\n",
    "　以下の式で表されるパラメータの更新式のメソッド_gradient_descentを追加し、fitメソッドから呼び出すようにしてください。<br>\n",
    "<br>\n",
    "　　　　$ \\theta_j := \\theta_j - \\alpha\\displaystyle\\frac{1}{m}\\displaystyle\\sum_{i=1}^{m}[h_{\\theta}(x^{(i)}) - y^{(i)})x_j^{(i)}] $<br>\n",
    "<br>\n",
    "　$ \\alpha $ ：学習率<br>\n",
    "　$ i $ ：サンプルのインデックス<br>\n",
    "　$ j $ ：特徴量のインデックス<br>\n",
    "<br>\n",
    "　<b>雛形</b><br>\n",
    "　ScratchLinearRegressionクラスへ以下のメソッドを追加してください。コメントアウト部分の説明も記述してください。<br>\n",
    "```\n",
    "def _gradient_descent(self, X, error):\n",
    "    \"\"\"\n",
    "    説明を記述\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "```\n",
    "　雛形として用意されたメソッドや関数以外でも必要があれば各自作成して完成させてください。雛形を外れても問題ありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2406e3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# class ScratchLinearRegression():\n",
    "#     \"\"\"\n",
    "#     線形回帰のスクラッチ実装\n",
    "    \n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     num_iter : int\n",
    "#       イテレーション数\n",
    "#     lr : float\n",
    "#       学習率\n",
    "#     no_bias : bool\n",
    "#       バイアス項を入れない場合はTrue\n",
    "#     verbose : bool\n",
    "#       学習過程を出力する場合はTrue\n",
    "    \n",
    "#     Attributes\n",
    "#     ----------\n",
    "#     self.coef_ : 次の形のndarray, shape (n_features,)\n",
    "#       パラメータ\n",
    "#     self.loss : 次の形のndarray, shape (self.iter,)\n",
    "#       訓練データに対する損失の記録\n",
    "#     self.val_loss : 次の形のndarray, shape (self.iter,)\n",
    "#       検証データに対する損失の記録\n",
    "#     \"\"\"\n",
    "    \n",
    "#     def __init__(self, num_iter, lr, no_bias, verbose):\n",
    "#         # ハイパーパラメータを属性として記録\n",
    "#         self.iter = num_iter\n",
    "#         self.lr = lr\n",
    "#         self.no_bias = no_bias\n",
    "#         self.verbose = verbose\n",
    "\n",
    "#         # 損失を記録する配列を用意\n",
    "#         self.loss = np.zeros(self.iter)\n",
    "#         self.val_loss = np.zeros(self.iter)\n",
    "\n",
    "#     def fit(self, X, y, X_val=None, y_val=None):\n",
    "#         \"\"\"\n",
    "#         線形回帰を学習する。検証データが入力された場合はそれに対する損失と精度もイテレーションごとに計算する。\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         X : 次の形のndarray, shape (n_samples, n_features)\n",
    "#             訓練データの特徴量\n",
    "#         y : 次の形のndarray, shape (n_samples, )\n",
    "#             訓練データの正解値\n",
    "#         X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "#             検証データの特徴量\n",
    "#         y_val : 次の形のndarray, shape (n_samples, )\n",
    "#             検証データの正解値\n",
    "#         \"\"\"\n",
    "#         if self.verbose:\n",
    "#             #verboseをTrueにした際は学習過程を出力\n",
    "#             print()\n",
    "#         else:\n",
    "#             # 問題1（過程関数の計算）\n",
    "#             self._linear_hypothesis(X)\n",
    "\n",
    "#             # 実際のyの値と仮定関数から導き出されたyの値を比較\n",
    "#             error = []\n",
    "#             for katei_y in self.hypothetical_y :\n",
    "#                 error.append(katei_y - y)\n",
    "\n",
    "#             # 問題2（最急降下法によるパラメータの更新値計算）\n",
    "#             self._gradient_descent(X, error)\n",
    "\n",
    "#             # 問題7（学習曲線のプロット）のグラフ描画時（問題5（損失関数）で作成した関数を使用）\n",
    "#             self._loss_func(・・・)\n",
    "\n",
    "#         pass\n",
    "\n",
    "#     def _linear_hypothesis(self, X):\n",
    "#         \"\"\"\n",
    "#         線形の仮定関数を計算する\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         X : 次の形のndarray, shape (n_samples, n_features)\n",
    "#           訓練データ\n",
    "#         Returns\n",
    "#         -------\n",
    "#         hypothetical_y : 次の形のndarray, shape (n_samples, 1)\n",
    "#           線形の仮定関数による推定結果\n",
    "#         \"\"\"\n",
    "\n",
    "#         # Xの1列目に「1」を埋める theta0の値のため\n",
    "#         zeroplus_X = np.array([[1, i] for i in X])\n",
    "\n",
    "#         # ランダムな値をtheta0, theta1の初期値に設定する\n",
    "#         self.theta = np.random.random(len(zeroplus_X[0]))\n",
    "\n",
    "#         # 転置行列積\n",
    "#         self.hypothetical_y = theta.T @ zeroplus_X.T\n",
    "\n",
    "#         return\n",
    "\n",
    "#     def _gradient_descent(self, X, error):\n",
    "#         \"\"\"\n",
    "#         説明を記述\n",
    "#         \"\"\"\n",
    "#         for i in range(len(X)):\n",
    "#             if i == 0:\n",
    "#                 new_theta = error[i] * X[i]\n",
    "# #                 print(\"i:{}\".format(i))\n",
    "# #                 print(\"error[i]:{}\".format(error[i]))\n",
    "# #                 print(\"X[i]:{}\".format(X[i]))\n",
    "# #                 print(\"new_theta:{}\".format(new_theta))\n",
    "# #                 print(\"=================================\")\n",
    "#             else:\n",
    "#                 new_theta += error[i] * X[i]\n",
    "# #                 print(\"i:{}\".format(i))\n",
    "# #                 print(\"error[i]:{}\".format(error[i]))\n",
    "# #                 print(\"X[i]:{}\".format(X[i]))\n",
    "# #                 print(\"new_theta:{}\".format(new_theta))\n",
    "# #                 print(\"=================================\")\n",
    "#         self.theta = self.theta - alpha * 1 / len(X) * new_theta\n",
    "# #         print(new_theta)\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         \"\"\"\n",
    "#         線形回帰を使い推定する。\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         X : 次の形のndarray, shape (n_samples, n_features)\n",
    "#             サンプル\n",
    "#         Returns\n",
    "#         -------\n",
    "#             次の形のndarray, shape (n_samples, 1)\n",
    "#             線形回帰による推定結果\n",
    "#         \"\"\"\n",
    "        \n",
    "#         return\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7502b557",
   "metadata": {},
   "source": [
    "### 【問題3】推定\n",
    "　推定する仕組みを実装してください。ScratchLinearRegressionクラスの雛形に含まれるpredictメソッドに書き加えてください。<br>\n",
    "\n",
    "仮定関数 $ h_{\\theta}(x) $ の出力が推定結果です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43d36273",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# class ScratchLinearRegression():\n",
    "#     \"\"\"\n",
    "#     線形回帰のスクラッチ実装\n",
    "    \n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     num_iter : int\n",
    "#       イテレーション数\n",
    "#     lr : float\n",
    "#       学習率\n",
    "#     no_bias : bool\n",
    "#       バイアス項を入れない場合はTrue\n",
    "#     verbose : bool\n",
    "#       学習過程を出力する場合はTrue\n",
    "    \n",
    "#     Attributes\n",
    "#     ----------\n",
    "#     self.coef_ : 次の形のndarray, shape (n_features,)\n",
    "#       パラメータ\n",
    "#     self.loss : 次の形のndarray, shape (self.iter,)\n",
    "#       訓練データに対する損失の記録\n",
    "#     self.val_loss : 次の形のndarray, shape (self.iter,)\n",
    "#       検証データに対する損失の記録\n",
    "#     \"\"\"\n",
    "    \n",
    "#     def __init__(self, num_iter, lr, no_bias, verbose):\n",
    "#         # ハイパーパラメータを属性として記録\n",
    "#         self.iter = num_iter\n",
    "#         self.lr = lr\n",
    "#         self.no_bias = no_bias\n",
    "#         self.verbose = verbose\n",
    "\n",
    "#         # 損失を記録する配列を用意\n",
    "#         self.loss = np.zeros(self.iter)\n",
    "#         self.val_loss = np.zeros(self.iter)\n",
    "\n",
    "#     def fit(self, X, y, X_val=None, y_val=None):\n",
    "#         \"\"\"\n",
    "#         線形回帰を学習する。検証データが入力された場合はそれに対する損失と精度もイテレーションごとに計算する。\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         X : 次の形のndarray, shape (n_samples, n_features)\n",
    "#             訓練データの特徴量\n",
    "#         y : 次の形のndarray, shape (n_samples, )\n",
    "#             訓練データの正解値\n",
    "#         X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "#             検証データの特徴量\n",
    "#         y_val : 次の形のndarray, shape (n_samples, )\n",
    "#             検証データの正解値\n",
    "#         \"\"\"\n",
    "#         if self.verbose:\n",
    "#             #verboseをTrueにした際は学習過程を出力\n",
    "#             print()\n",
    "#         else:\n",
    "#             # 問題1（過程関数の計算）\n",
    "#             self._linear_hypothesis(X)\n",
    "\n",
    "#             # 実際のyの値と仮定関数から導き出されたyの値を比較\n",
    "#             error = []\n",
    "#             for katei_y in self.hypothetical_y :\n",
    "#                 error.append(katei_y - y)\n",
    "\n",
    "#             # 問題2（最急降下法によるパラメータの更新値計算）\n",
    "#             self._gradient_descent(X, error)\n",
    "\n",
    "#             # 問題7（学習曲線のプロット）のグラフ描画時（問題5（損失関数）で作成した関数を使用）\n",
    "#             self._loss_func(・・・)\n",
    "\n",
    "#         pass\n",
    "\n",
    "#     def _linear_hypothesis(self, X):\n",
    "#         \"\"\"\n",
    "#         線形の仮定関数を計算する\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         X : 次の形のndarray, shape (n_samples, n_features)\n",
    "#           訓練データ\n",
    "#         Returns\n",
    "#         -------\n",
    "#         hypothetical_y : 次の形のndarray, shape (n_samples, 1)\n",
    "#           線形の仮定関数による推定結果\n",
    "#         \"\"\"\n",
    "\n",
    "#         # Xの1列目に「1」を埋める theta0の値のため\n",
    "#         zeroplus_X = np.array([[1, i] for i in X])\n",
    "\n",
    "#         # ランダムな値をtheta0, theta1の初期値に設定する\n",
    "#         self.theta = np.random.random(len(zeroplus_X[0]))\n",
    "\n",
    "#         # 転置行列積\n",
    "#         self.hypothetical_y = self.theta.T @ zeroplus_X.T\n",
    "\n",
    "#         return\n",
    "\n",
    "#     def _gradient_descent(self, X, error):\n",
    "#         \"\"\"\n",
    "#         説明を記述\n",
    "#         \"\"\"\n",
    "#         for i in range(len(X)):\n",
    "#             if i == 0:\n",
    "#                 new_theta = error[i] * X[i]\n",
    "# #                 print(\"i:{}\".format(i))\n",
    "# #                 print(\"error[i]:{}\".format(error[i]))\n",
    "# #                 print(\"X[i]:{}\".format(X[i]))\n",
    "# #                 print(\"new_theta:{}\".format(new_theta))\n",
    "# #                 print(\"=================================\")\n",
    "#             else:\n",
    "#                 new_theta += error[i] * X[i]\n",
    "# #                 print(\"i:{}\".format(i))\n",
    "# #                 print(\"error[i]:{}\".format(error[i]))\n",
    "# #                 print(\"X[i]:{}\".format(X[i]))\n",
    "# #                 print(\"new_theta:{}\".format(new_theta))\n",
    "# #                 print(\"=================================\")\n",
    "#         self.theta = self.theta - alpha * 1 / len(X) * new_theta\n",
    "# #         print(new_theta)\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         \"\"\"\n",
    "#         線形回帰を使い推定する。\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         X : 次の形のndarray, shape (n_samples, n_features)\n",
    "#             サンプル\n",
    "#         Returns\n",
    "#         -------\n",
    "#             次の形のndarray, shape (n_samples, 1)\n",
    "#             線形回帰による推定結果\n",
    "#         \"\"\"\n",
    "#         # 転置行列積\n",
    "#         self.predict_y = self.theta.T @ zeroplus_X.T\n",
    "\n",
    "#         return\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4671a8f4",
   "metadata": {},
   "source": [
    "### 【問題4】平均二乗誤差\n",
    "　線形回帰の指標値として用いられる平均二乗誤差（mean square error, MSE）の関数を作成してください。<br>\n",
    "<br>\n",
    "　平均二乗誤差関数は回帰問題全般で使える関数のため、ScratchLinearRegressionクラスのメソッドではなく、別の関数として作成してください。雛形を用意してあります。<br>\n",
    "<br>\n",
    "　平均二乗誤差は以下の数式で表されます。<br>\n",
    "<br>\n",
    "　　　　$ L({\\theta}) = \\displaystyle\\frac{1}{m}\\displaystyle\\sum_{i=1}^{m}(h_{\\theta}(x^{(i)}) - y^{(i)})^2 $<br>\n",
    "<br>\n",
    "　$ m $ : 入力されるデータの数<br>\n",
    "　$ h_\\theta() $ : 仮定関数<br>\n",
    "　$ x^{(i)} $ : i番目のサンプルの特徴量ベクトル<br>\n",
    "　$ y^{(i)} $ : i番目のサンプルの正解値<br>\n",
    "<br>\n",
    "　なお、最急降下法のための目的関数（損失関数）としては、これを2で割ったものを使用します。（問題5, 9）<br>\n",
    "<br>\n",
    "　<b> 雛形 </b>\n",
    "<br>\n",
    "```\n",
    "def MSE(y_pred, y):\n",
    "    \"\"\"\n",
    "    平均二乗誤差の計算\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_pred : 次の形のndarray, shape (n_samples,)\n",
    "      推定した値\n",
    "    y : 次の形のndarray, shape (n_samples,)\n",
    "      正解値\n",
    "    Returns\n",
    "    ----------\n",
    "    mse : numpy.float\n",
    "      平均二乗誤差\n",
    "    \"\"\"\n",
    "    pass\n",
    "    return mse\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4583cbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# class ScratchLinearRegression():\n",
    "#     \"\"\"\n",
    "#     線形回帰のスクラッチ実装\n",
    "    \n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     num_iter : int\n",
    "#       イテレーション数\n",
    "#     lr : float\n",
    "#       学習率\n",
    "#     no_bias : bool\n",
    "#       バイアス項を入れない場合はTrue\n",
    "#     verbose : bool\n",
    "#       学習過程を出力する場合はTrue\n",
    "    \n",
    "#     Attributes\n",
    "#     ----------\n",
    "#     self.coef_ : 次の形のndarray, shape (n_features,)\n",
    "#       パラメータ\n",
    "#     self.loss : 次の形のndarray, shape (self.iter,)\n",
    "#       訓練データに対する損失の記録\n",
    "#     self.val_loss : 次の形のndarray, shape (self.iter,)\n",
    "#       検証データに対する損失の記録\n",
    "#     \"\"\"\n",
    "    \n",
    "#     def __init__(self, num_iter, lr, no_bias, verbose):\n",
    "#         # ハイパーパラメータを属性として記録\n",
    "#         self.iter = num_iter\n",
    "#         self.lr = lr\n",
    "#         self.no_bias = no_bias\n",
    "#         self.verbose = verbose\n",
    "\n",
    "#         # 損失を記録する配列を用意\n",
    "#         self.loss = np.zeros(self.iter)\n",
    "#         self.val_loss = np.zeros(self.iter)\n",
    "\n",
    "#     def fit(self, X, y, X_val=None, y_val=None):\n",
    "#         \"\"\"\n",
    "#         線形回帰を学習する。検証データが入力された場合はそれに対する損失と精度もイテレーションごとに計算する。\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         X : 次の形のndarray, shape (n_samples, n_features)\n",
    "#             訓練データの特徴量\n",
    "#         y : 次の形のndarray, shape (n_samples, )\n",
    "#             訓練データの正解値\n",
    "#         X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "#             検証データの特徴量\n",
    "#         y_val : 次の形のndarray, shape (n_samples, )\n",
    "#             検証データの正解値\n",
    "#         \"\"\"\n",
    "#         if self.verbose:\n",
    "#             #verboseをTrueにした際は学習過程を出力\n",
    "#             print()\n",
    "#         else:\n",
    "#             # 問題1（過程関数の計算）\n",
    "#             self._linear_hypothesis(X)\n",
    "\n",
    "#             # 実際のyの値と仮定関数から導き出されたyの値を比較\n",
    "#             error = []\n",
    "#             for katei_y in self.hypothetical_y :\n",
    "#                 error.append(katei_y - y)\n",
    "\n",
    "#             # 問題2（最急降下法によるパラメータの更新値計算）\n",
    "#             self._gradient_descent(X, error)\n",
    "\n",
    "#             # 問題7（学習曲線のプロット）のグラフ描画時（問題5（損失関数）で作成した関数を使用）\n",
    "#             self._loss_func(・・・)\n",
    "\n",
    "#         pass\n",
    "\n",
    "#     def _linear_hypothesis(self, X):\n",
    "#         \"\"\"\n",
    "#         線形の仮定関数を計算する\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         X : 次の形のndarray, shape (n_samples, n_features)\n",
    "#           訓練データ\n",
    "#         Returns\n",
    "#         -------\n",
    "#         hypothetical_y : 次の形のndarray, shape (n_samples, 1)\n",
    "#           線形の仮定関数による推定結果\n",
    "#         \"\"\"\n",
    "\n",
    "#         # Xの1列目に「1」を埋める theta0の値のため\n",
    "#         zeroplus_X = np.array([[1, i] for i in X])\n",
    "\n",
    "#         # ランダムな値をtheta0, theta1の初期値に設定する\n",
    "#         self.theta = np.random.random(len(zeroplus_X[0]))\n",
    "\n",
    "#         # 転置行列積\n",
    "#         self.hypothetical_y = self.theta.T @ zeroplus_X.T\n",
    "\n",
    "#         return\n",
    "\n",
    "#     def _gradient_descent(self, X, error):\n",
    "#         \"\"\"\n",
    "#         説明を記述\n",
    "#         \"\"\"\n",
    "#         for i in range(len(X)):\n",
    "#             if i == 0:\n",
    "#                 new_theta = error[i] * X[i]\n",
    "# #                 print(\"i:{}\".format(i))\n",
    "# #                 print(\"error[i]:{}\".format(error[i]))\n",
    "# #                 print(\"X[i]:{}\".format(X[i]))\n",
    "# #                 print(\"new_theta:{}\".format(new_theta))\n",
    "# #                 print(\"=================================\")\n",
    "#             else:\n",
    "#                 new_theta += error[i] * X[i]\n",
    "# #                 print(\"i:{}\".format(i))\n",
    "# #                 print(\"error[i]:{}\".format(error[i]))\n",
    "# #                 print(\"X[i]:{}\".format(X[i]))\n",
    "# #                 print(\"new_theta:{}\".format(new_theta))\n",
    "# #                 print(\"=================================\")\n",
    "#         self.theta = self.theta - alpha * 1 / len(X) * new_theta\n",
    "# #         print(new_theta)\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         \"\"\"\n",
    "#         線形回帰を使い推定する。\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         X : 次の形のndarray, shape (n_samples, n_features)\n",
    "#             サンプル\n",
    "#         Returns\n",
    "#         -------\n",
    "#             次の形のndarray, shape (n_samples, 1)\n",
    "#             線形回帰による推定結果\n",
    "#         \"\"\"\n",
    "#         # 転置行列積\n",
    "#         self.predict_y = self.theta.T @ zeroplus_X.T\n",
    "\n",
    "#         return\n",
    "\n",
    "#     def MSE(y_pred, y):\n",
    "#         \"\"\"\n",
    "#         平均二乗誤差の計算\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         y_pred : 次の形のndarray, shape (n_samples,)\n",
    "#           推定した値\n",
    "#         y : 次の形のndarray, shape (n_samples,)\n",
    "#           正解値\n",
    "#         Returns\n",
    "#         ----------\n",
    "#         mse : numpy.float\n",
    "#           平均二乗誤差\n",
    "#         \"\"\"\n",
    "#         for i in len(y):\n",
    "#             if i == 0:\n",
    "#                 mse = (y_pred(i) - y(i)) ** 2\n",
    "#             else:\n",
    "#                 mse += ((y_pred(i) - y(i)) ** 2)\n",
    "#         mse = 1 / len(y) * mse\n",
    "\n",
    "#         return mse\n",
    "\n",
    "#     def _loss_func(self,・・・):\n",
    "#         \"\"\"\n",
    "#         損失関数\n",
    "#         \"\"\"\n",
    "#         # 問題4\n",
    "#         self._mse(・・・)\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c4a0c6",
   "metadata": {},
   "source": [
    "### 【問題5】目的関数\n",
    "　以下の数式で表される線形回帰の 目的関数（損失関数） を実装してください。そして、これを<b><span style=\"color: red; \">self.loss</span></b>, <b><span style=\"color: red; \">self.val_loss</span></b>に記録するようにしてください。<br>\n",
    "<br>\n",
    "　目的関数（損失関数） $ J(\\theta) $ は次の式です。<br>\n",
    "<br>\n",
    "　　　　$ J(\\theta) = \\displaystyle\\frac{1}{2m}\\displaystyle\\sum_{i=1}^{m}(h_{\\theta}(x^{(i)}) - y^{(i)})^2 $<br>\n",
    "<br>\n",
    "　$ m $ : 入力されるデータの数<br>\n",
    "　$ h_\\theta() $ : 仮定関数<br>\n",
    "　$ x^{(i)} $ : i番目のサンプルの特徴量ベクトル<br>\n",
    "　$ y^{(i)} $ : i番目のサンプルの正解値<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18e46938",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# class ScratchLinearRegression():\n",
    "#     \"\"\"\n",
    "#     線形回帰のスクラッチ実装\n",
    "    \n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     num_iter : int\n",
    "#       イテレーション数\n",
    "#     lr : float\n",
    "#       学習率\n",
    "#     no_bias : bool\n",
    "#       バイアス項を入れない場合はTrue\n",
    "#     verbose : bool\n",
    "#       学習過程を出力する場合はTrue\n",
    "    \n",
    "#     Attributes\n",
    "#     ----------\n",
    "#     self.coef_ : 次の形のndarray, shape (n_features,)\n",
    "#       パラメータ\n",
    "#     self.loss : 次の形のndarray, shape (self.iter,)\n",
    "#       訓練データに対する損失の記録\n",
    "#     self.val_loss : 次の形のndarray, shape (self.iter,)\n",
    "#       検証データに対する損失の記録\n",
    "#     \"\"\"\n",
    "    \n",
    "#     def __init__(self, num_iter, lr, no_bias, verbose):\n",
    "#         # ハイパーパラメータを属性として記録\n",
    "#         self.iter = num_iter\n",
    "#         self.lr = lr\n",
    "#         self.no_bias = no_bias\n",
    "#         self.verbose = verbose\n",
    "\n",
    "#         # 損失を記録する配列を用意\n",
    "#         self.loss = np.zeros(self.iter)\n",
    "#         self.val_loss = np.zeros(self.iter)\n",
    "\n",
    "#     def fit(self, X, y, X_val=None, y_val=None):\n",
    "#         \"\"\"\n",
    "#         線形回帰を学習する。検証データが入力された場合はそれに対する損失と精度もイテレーションごとに計算する。\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         X : 次の形のndarray, shape (n_samples, n_features)\n",
    "#             訓練データの特徴量\n",
    "#         y : 次の形のndarray, shape (n_samples, )\n",
    "#             訓練データの正解値\n",
    "#         X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "#             検証データの特徴量\n",
    "#         y_val : 次の形のndarray, shape (n_samples, )\n",
    "#             検証データの正解値\n",
    "#         \"\"\"\n",
    "#         if self.verbose:\n",
    "#             #verboseをTrueにした際は学習過程を出力\n",
    "#             print()\n",
    "#         else:\n",
    "#             # 問題1（過程関数の計算）\n",
    "#             self._linear_hypothesis(X)\n",
    "\n",
    "#             # 実際のyの値と仮定関数から導き出されたyの値を比較\n",
    "#             error = []\n",
    "#             for katei_y in self.hypothetical_y :\n",
    "#                 error.append(katei_y - y)\n",
    "\n",
    "#             # 問題2（最急降下法によるパラメータの更新値計算）\n",
    "#             self._gradient_descent(X, error)\n",
    "\n",
    "#             # 問題7（学習曲線のプロット）のグラフ描画時（問題5（損失関数）で作成した関数を使用）\n",
    "#             self._loss_func(・・・)\n",
    "\n",
    "#         pass\n",
    "\n",
    "#     def _linear_hypothesis(self, X):\n",
    "#         \"\"\"\n",
    "#         線形の仮定関数を計算する\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         X : 次の形のndarray, shape (n_samples, n_features)\n",
    "#           訓練データ\n",
    "#         Returns\n",
    "#         -------\n",
    "#         hypothetical_y : 次の形のndarray, shape (n_samples, 1)\n",
    "#           線形の仮定関数による推定結果\n",
    "#         \"\"\"\n",
    "\n",
    "#         # Xの1列目に「1」を埋める theta0の値のため\n",
    "#         zeroplus_X = np.array([[1, i] for i in X])\n",
    "\n",
    "#         # ランダムな値をtheta0, theta1の初期値に設定する\n",
    "#         self.theta = np.random.random(len(zeroplus_X[0]))\n",
    "\n",
    "#         # 転置行列積\n",
    "#         self.hypothetical_y = self.theta.T @ zeroplus_X.T\n",
    "\n",
    "#         return\n",
    "\n",
    "#     def _gradient_descent(self, X, error):\n",
    "#         \"\"\"\n",
    "#         説明を記述\n",
    "#         \"\"\"\n",
    "#         for i in range(len(X)):\n",
    "#             if i == 0:\n",
    "#                 new_theta = error[i] * X[i]\n",
    "# #                 print(\"i:{}\".format(i))\n",
    "# #                 print(\"error[i]:{}\".format(error[i]))\n",
    "# #                 print(\"X[i]:{}\".format(X[i]))\n",
    "# #                 print(\"new_theta:{}\".format(new_theta))\n",
    "# #                 print(\"=================================\")\n",
    "#             else:\n",
    "#                 new_theta += error[i] * X[i]\n",
    "# #                 print(\"i:{}\".format(i))\n",
    "# #                 print(\"error[i]:{}\".format(error[i]))\n",
    "# #                 print(\"X[i]:{}\".format(X[i]))\n",
    "# #                 print(\"new_theta:{}\".format(new_theta))\n",
    "# #                 print(\"=================================\")\n",
    "#         self.theta = self.theta - alpha * 1 / len(X) * new_theta\n",
    "# #         print(new_theta)\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         \"\"\"\n",
    "#         線形回帰を使い推定する。\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         X : 次の形のndarray, shape (n_samples, n_features)\n",
    "#             サンプル\n",
    "#         Returns\n",
    "#         -------\n",
    "#             次の形のndarray, shape (n_samples, 1)\n",
    "#             線形回帰による推定結果\n",
    "#         \"\"\"\n",
    "#         # 転置行列積\n",
    "#         self.predict_y = self.theta.T @ zeroplus_X.T\n",
    "\n",
    "#         return\n",
    "\n",
    "#     def MSE(y_pred, y):\n",
    "#         \"\"\"\n",
    "#         平均二乗誤差の計算\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         y_pred : 次の形のndarray, shape (n_samples,)\n",
    "#           推定した値\n",
    "#         y : 次の形のndarray, shape (n_samples,)\n",
    "#           正解値\n",
    "#         Returns\n",
    "#         ----------\n",
    "#         mse : numpy.float\n",
    "#           平均二乗誤差\n",
    "#         \"\"\"\n",
    "#         for i in len(y):\n",
    "#             if i == 0:\n",
    "#                 mse = (y_pred(i) - y(i)) ** 2\n",
    "#             else:\n",
    "#                 mse += ((y_pred(i) - y(i)) ** 2)\n",
    "#         mse = 1 / len(y) * mse\n",
    "\n",
    "#         return mse\n",
    "\n",
    "#     def _loss_func(self,y_pred, y):\n",
    "#         \"\"\"\n",
    "#         損失関数\n",
    "#         \"\"\"\n",
    "#         for i in range(len(y)):\n",
    "#             if i == 0:\n",
    "#                 purpose_y = (y_pred[i] - y[i]) ** 2\n",
    "#             else:\n",
    "#                 purpose_y += ((y_pred[i] - y[i]) ** 2)\n",
    "\n",
    "#         self.los = 1 / (2 * len(y)) * purpose_y\n",
    "\n",
    "#         # 問題4\n",
    "#         self.val_loss = self._mse(y_pred, y)\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5880d839",
   "metadata": {},
   "source": [
    "### 【問題6】学習と推定\n",
    "　機械学習スクラッチ入門のSprintで用意したHouse Pricesコンペティションのデータに対してスクラッチ実装の学習と推定を行なってください。<br>\n",
    "　scikit-learnによる実装と比べ、正しく動いているかを確認してください。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "972ff71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "\n",
    "# class ScratchLinearRegression():\n",
    "#     \"\"\"\n",
    "#     線形回帰のスクラッチ実装\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     num_iter : int\n",
    "#       イテレーション数\n",
    "#     lr : float\n",
    "#       学習率\n",
    "#     no_bias : bool\n",
    "#       バイアス項を入れない場合はTrue\n",
    "#     verbose : bool\n",
    "#       学習過程を出力する場合はTrue\n",
    "\n",
    "#     Attributes\n",
    "#     ----------\n",
    "#     self.coef_ : 次の形のndarray, shape (n_features,)\n",
    "#       パラメータ\n",
    "#     self.loss : 次の形のndarray, shape (self.iter,)\n",
    "#       訓練データに対する損失の記録\n",
    "#     self.val_loss : 次の形のndarray, shape (self.iter,)\n",
    "#       検証データに対する損失の記録\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, num_iter, lr, no_bias=False, verbose=False):\n",
    "#         # ハイパーパラメータを属性として記録\n",
    "#         self.iter = num_iter\n",
    "#         self.lr = lr\n",
    "#         self.no_bias = no_bias\n",
    "#         self.verbose = verbose\n",
    "\n",
    "#         # 損失を記録する配列を用意\n",
    "#         # self.loss = np.zeros(self.iter)\n",
    "#         # self.val_loss = np.zeros(self.iter)\n",
    "#         self.loss = []\n",
    "#         self.val_loss = []\n",
    "\n",
    "#     def fit(self, X, y, X_val=None, y_val=None):\n",
    "#         \"\"\"\n",
    "#         線形回帰を学習する。検証データが入力された場合はそれに対する損失と精度もイテレーションごとに計算する。\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         X : 次の形のndarray, shape (n_samples, n_features)\n",
    "#             訓練データの特徴量\n",
    "#         y : 次の形のndarray, shape (n_samples, )\n",
    "#             訓練データの正解値\n",
    "#         X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "#             検証データの特徴量\n",
    "#         y_val : 次の形のndarray, shape (n_samples, )\n",
    "#             検証データの正解値\n",
    "#         \"\"\"\n",
    "#         # Xの1列目に「1」を入れる\n",
    "#         zeroplus_X = np.insert(X, 0, 1, axis = 1 )\n",
    "\n",
    "#         for i in range(self.iter):\n",
    "#             # 問題1（過程関数の計算）\n",
    "#             self._linear_hypothesis(zeroplus_X)\n",
    "\n",
    "#             # 仮定関数から導き出されたyの値から実際のyの値を引いて比較\n",
    "#             error = self.hypothetical_y - y\n",
    "\n",
    "#             # 問題2（最急降下法によるパラメータの更新値計算）\n",
    "#             self._gradient_descent(zeroplus_X, error)\n",
    "#             # self._gradient_descent(X, error)\n",
    "\n",
    "#             # 問題7（学習曲線のプロット）のグラフ描画時（問題5（損失関数）で作成した関数を使用）\n",
    "#             self._loss_func(y)\n",
    "\n",
    "#     def _linear_hypothesis(self, zeroplus_X):\n",
    "#         \"\"\"\n",
    "#         線形の仮定関数を計算する\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         zeroplus_X : 次の形のndarray, shape (n_samples, n_features)\n",
    "#           訓練データ\n",
    "#         Returns\n",
    "#         -------\n",
    "#         self.hypothetical_y : 次の形のndarray, shape (n_samples, 1)\n",
    "#           線形の仮定関数による推定結果\n",
    "#         \"\"\"\n",
    "\n",
    "#         # 「self.theta」が定義されている場合、存在している「self.theta」を使用、存在していない場合(初回のみのはず)はランダムな値を使用\n",
    "#         if \"self.theta\" in locals():\n",
    "#             pass\n",
    "#         else:\n",
    "#             # ランダムな値をtheta0, theta1の初期値に設定する\n",
    "#             self.theta = np.random.random(len(zeroplus_X[0]))\n",
    "\n",
    "#         # 転置行列積\n",
    "#         self.hypothetical_y = self.theta.T @ zeroplus_X.T\n",
    "#         # self.hypothetical_y = self.theta.T @ X.T\n",
    "\n",
    "\n",
    "#     def _gradient_descent(self, X, error):\n",
    "#         \"\"\"\n",
    "#         説明を記述\n",
    "#         \"\"\"\n",
    "#         for i in range(len(X)):\n",
    "#             if i == 0:\n",
    "#                 new_theta = error[i] * X[i]\n",
    "#             else:\n",
    "#                 new_theta += (error[i] * X[i])\n",
    "\n",
    "#         # 次のθへ更新\n",
    "#         self.theta = self.theta - lr * 1 / len(X) * new_theta\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         \"\"\"\n",
    "#         線形回帰を使い推定する。\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         X : 次の形のndarray, shape (n_samples, n_features)\n",
    "#             サンプル\n",
    "#         Returns\n",
    "#         -------\n",
    "#             次の形のndarray, shape (n_samples, 1)\n",
    "#             線形回帰による推定結果\n",
    "#         \"\"\"\n",
    "# #         print(\"===== self.theta =============================================\")\n",
    "# #         print(type(self.theta))\n",
    "# #         print(self.theta.shape)\n",
    "# #         print(self.theta)\n",
    "# #         print(\"===== X =============================================\")\n",
    "# #         print(type(X))\n",
    "# #         print(X.shape)\n",
    "# #         print(X)\n",
    "\n",
    "#         # Xの1列目に「1」を入れる\n",
    "#         zeroplus_X = np.insert(X, 0, 1, axis = 1 )\n",
    "\n",
    "#         # 転置行列積\n",
    "#         predict_y = self.theta.T @ zeroplus_X.T\n",
    "# #         print(\"===== predict_y =============================================\")\n",
    "# #         print(type(predict_y))\n",
    "# #         print(predict_y.shape)\n",
    "# #         print(predict_y)\n",
    "#         print(\"===== self.loss =============================================\")\n",
    "#         print(type(self.loss))\n",
    "#         print(len(self.loss))\n",
    "#         print(self.loss)\n",
    "#         print(\"===== self.val_loss =============================================\")\n",
    "#         print(type(self.val_loss))\n",
    "#         print(len(self.val_loss))\n",
    "#         print(self.val_loss)\n",
    "\n",
    "#         return predict_y\n",
    "\n",
    "\n",
    "#     # def _loss_func(self, y_pred, y):\n",
    "#     def _loss_func(self, y):\n",
    "#         \"\"\"\n",
    "#         損失関数\n",
    "#         \"\"\"\n",
    "#         for i in range(len(y)):\n",
    "#             if i == 0:\n",
    "#                 purpose_y = (self.hypothetical_y[i] - y[i]) ** 2\n",
    "#             else:\n",
    "#                 purpose_y += ((self.hypothetical_y[i] - y[i]) ** 2)\n",
    "\n",
    "#         # \n",
    "#         self.loss.append(1 / (2 * len(y)) * purpose_y)\n",
    "#         # self.loss = 1 / (2 * len(y)) * purpose_y\n",
    "\n",
    "#         # 問題4\n",
    "#         self.val_loss.append(MSE(self.hypothetical_y, y))\n",
    "#         # self.val_loss = MSE(self.hypothetical_y, y)\n",
    "\n",
    "\n",
    "# def MSE(hypothetical_y, y):\n",
    "#     \"\"\"\n",
    "#     平均二乗誤差の計算\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     y_pred : 次の形のndarray, shape (n_samples,)\n",
    "#       推定した値\n",
    "#     y : 次の形のndarray, shape (n_samples,)\n",
    "#       正解値\n",
    "#     Returns\n",
    "#     ----------\n",
    "#     mse : numpy.float\n",
    "#       平均二乗誤差\n",
    "#     \"\"\"\n",
    "#     for i in range(len(y)):\n",
    "#         if i == 0:\n",
    "# #             print(\"=============================================\")\n",
    "# #             print(hypothetical_y)\n",
    "# #             print(type(hypothetical_y))\n",
    "# #             print(hypothetical_y.shape)\n",
    "# #             print(\"=============================================\")\n",
    "# #             print(y)\n",
    "# #             print(type(y))\n",
    "# #             print(y.shape)\n",
    "#             mse = (hypothetical_y[i] - y[i] ** 2)\n",
    "#         else:\n",
    "#             mse += ((hypothetical_y[i] - y[i]) ** 2)\n",
    "#     mse = 1 / len(y) * mse\n",
    "\n",
    "#     return mse\n",
    "\n",
    "\n",
    "# # ファイル名（パス）を指定する\n",
    "# csv_path = \"E:/DiveIntoCode/source/train.csv\" # 絶対パス\n",
    "\n",
    "# # 指数表示の禁止を設定する\n",
    "# np.set_printoptions(suppress=True)\n",
    "\n",
    "# # csvファイル読み込み\n",
    "# df_train = pd.read_csv(csv_path)\n",
    "\n",
    "# # Xに説明変数、yに目的変数となる列をそれぞれ抽出して代入\n",
    "# df_X = df_train[[\"GrLivArea\",\"YearBuilt\"]]\n",
    "# df_y = df_train[\"SalePrice\"]\n",
    "# # print(df_X, df_y)\n",
    "# # X,yをndarrayへ変換\n",
    "# X = df_X.values\n",
    "# y = df_y.values\n",
    "\n",
    "# # # 標準化しないで進める？\n",
    "# # # インスタンス化\n",
    "# # scaler = StandardScaler()\n",
    "# # # 訓練用のデータのみを.fitで標準化\n",
    "# # fit_X_tarin = scaler.fit(X_train)\n",
    "# # # 訓練用、検証用双方のデータにtransformで標準化\n",
    "# # tr_X_tarin = scaler.transform(X_train)\n",
    "# # tr_X_test = scaler.transform(X_test)\n",
    "\n",
    "# # 線形回帰による学習\n",
    "# # ハイパーパラメータの設定\n",
    "# num_iter = 100 # イテレーション数\n",
    "# lr = 0.02 # 学習率\n",
    "\n",
    "# slr = ScratchLinearRegression(num_iter, lr)\n",
    "# reg = slr.fit(X, y)\n",
    "\n",
    "# # 学習モデルによる推定\n",
    "# Y_pred = slr.predict(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f688175",
   "metadata": {},
   "source": [
    "### 【問題7】学習曲線のプロット\n",
    "学習曲線を表示する関数を作成し、実行してください。グラフを見て損失が適切に下がっているかどうか確認してください。<br>\n",
    "<br>\n",
    "線形回帰クラスの雛形ではself.loss, self.val_lossに損失を記録しておくようになっているため、入力にはこれを利用してください。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "39735163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.06672597e+05 -3.53410141e+08 -4.13965212e+08]\n",
      "[-1.79746029e+05 -2.26839488e+08 -3.55178153e+08]\n",
      "[-3.86418626e+05 -5.80249629e+08 -7.69143365e+08]\n",
      "[6.14942806e+10 1.05155220e+14 1.23173044e+14]\n",
      "[5.42430629e+10 6.84547454e+13 1.07184292e+14]\n",
      "[1.15737344e+11 1.73609965e+14 2.30357336e+14]\n",
      "[-1.93324117e+16 -3.30584240e+19 -3.87228207e+19]\n",
      "[-1.71178417e+16 -2.16027163e+19 -3.38248553e+19]\n",
      "[-3.64502535e+16 -5.46611403e+19 -7.25476760e+19]\n",
      "[6.08267568e+21 1.04013754e+25 1.21835994e+25]\n",
      "[5.38639294e+21 6.79762789e+24 1.06435125e+25]\n",
      "[1.14690686e+22 1.71990033e+25 2.28271118e+25]\n",
      "[-1.91386823e+27 -3.27271467e+30 -3.83347806e+30]\n",
      "[-1.69479195e+27 -2.13882744e+30 -3.34890889e+30]\n",
      "[-3.60866017e+27 -5.41154210e+30 -7.18238694e+30]\n",
      "[6.02184562e+32 1.02973560e+36 1.20617568e+36]\n",
      "[5.33253851e+32 6.72966360e+35 1.05370961e+36]\n",
      "[1.13543841e+33 1.70270196e+36 2.25988529e+36]\n",
      "[-1.89472946e+38 -3.23998737e+41 -3.79514311e+41]\n",
      "[-1.67784405e+38 -2.11743919e+41 -3.31541984e+41]\n",
      "[-3.57257351e+38 -5.35742656e+41 -7.11056295e+41]\n",
      "[5.96162697e+43 1.01943821e+47 1.19411388e+47]\n",
      "[5.27921297e+43 6.66236676e+46 1.04317248e+47]\n",
      "[1.12408399e+44 1.68567489e+47 2.23728636e+47]\n",
      "[-1.87578210e+49 -3.20758740e+52 -3.75719156e+52]\n",
      "[-1.66106555e+49 -2.09626473e+52 -3.28226554e+52]\n",
      "[-3.53684766e+49 -5.30385213e+52 -7.03945709e+52]\n",
      "[5.90201051e+54 1.00924380e+58 1.18217271e+58]\n",
      "[5.22642067e+54 6.59574288e+57 1.03274072e+58]\n",
      "[1.11284312e+55 1.66881809e+58 2.21491343e+58]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class ScratchLinearRegression():\n",
    "    \"\"\"\n",
    "    線形回帰のスクラッチ実装\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    num_iter : int\n",
    "      イテレーション数\n",
    "    lr : float\n",
    "      学習率\n",
    "    no_bias : bool\n",
    "      バイアス項を入れない場合はTrue\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    self.coef_ : 次の形のndarray, shape (n_features,)\n",
    "      パラメータ\n",
    "    self.loss : 次の形のndarray, shape (self.iter,)\n",
    "      訓練データに対する損失の記録\n",
    "    self.val_loss : 次の形のndarray, shape (self.iter,)\n",
    "      検証データに対する損失の記録\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_iter, lr, no_bias=False, verbose=False):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.no_bias = no_bias\n",
    "        self.verbose = verbose\n",
    "\n",
    "        # 損失を記録する配列を用意\n",
    "        self.loss = np.zeros(self.iter)\n",
    "        self.val_loss = np.zeros(self.iter)\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        線形回帰を学習する。検証データが入力された場合はそれに対する損失と精度もイテレーションごとに計算する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        # Xの1列目に「1」を入れる\n",
    "        zeroplus_X = np.insert(X, 0, 1, axis = 1 )\n",
    "\n",
    "        # ランダムな値をself.thetaの初期値に設定する\n",
    "        self.theta = np.random.random(len(zeroplus_X[0]))\n",
    "\n",
    "        # 学習回数分ループ\n",
    "        for i in range(self.iter):\n",
    "\n",
    "            # 問題1（過程関数の計算）\n",
    "            self._linear_hypothesis(zeroplus_X)\n",
    "\n",
    "            # 仮定関数から導き出されたyの値から実際のyの値を引いて比較\n",
    "            error = self.hypothetical_y.reshape(self.hypothetical_y.shape[0], 1) - y\n",
    "\n",
    "            # 問題2（最急降下法によるパラメータの更新値計算）\n",
    "            self._gradient_descent(zeroplus_X, error)\n",
    "\n",
    "            # 問題7（学習曲線のプロット）のグラフ描画時（問題5（損失関数）で作成した関数を使用）\n",
    "            self._loss_func(error, i)\n",
    "\n",
    "\n",
    "    def _linear_hypothesis(self, zeroplus_X):\n",
    "        \"\"\"\n",
    "        線形の仮定関数を計算する\n",
    "        Parameters\n",
    "        ----------\n",
    "        zeroplus_X : 次の形のndarray, shape (n_samples, n_features)\n",
    "          訓練データ\n",
    "        Returns\n",
    "        -------\n",
    "         : 次の形のndarray, shape (n_samples, 1)\n",
    "          線形の仮定関数による推定結果\n",
    "        \"\"\"\n",
    "        # 転置行列積\n",
    "        self.hypothetical_y = self.theta.T @ zeroplus_X.T\n",
    "\n",
    "\n",
    "    def _gradient_descent(self, zeroplus_X, error):\n",
    "        \"\"\"\n",
    "        説明を記述\n",
    "        \"\"\"\n",
    "        for i in range(len(zeroplus_X)):\n",
    "            if i == 0:\n",
    "                new_theta = error[i] * zeroplus_X[i]\n",
    "            else:\n",
    "                new_theta += (error[i] * zeroplus_X[i])\n",
    "\n",
    "        # 次のθへ更新\n",
    "        self.theta = self.theta - (lr / len(zeroplus_X) * new_theta)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        線形回帰を使い推定する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            線形回帰による推定結果\n",
    "        \"\"\"\n",
    "        # Xの1列目に「1」を入れる\n",
    "        zeroplus_X = np.insert(X, 0, 1, axis = 1 )\n",
    "\n",
    "        # 転置行列積\n",
    "        predict_y = self.theta.T @ zeroplus_X.T\n",
    "\n",
    "        return predict_y\n",
    "\n",
    "\n",
    "    # def _loss_func(self, y_pred, y):\n",
    "    def _loss_func(self, error, i):\n",
    "        \"\"\"\n",
    "        損失関数\n",
    "        \"\"\"\n",
    "        # 問題4\n",
    "        mse = MSE(error)\n",
    "        self.val_loss[i] = mse\n",
    "\n",
    "        loss_num = mse / 2\n",
    "        self.loss[i] = loss_num\n",
    "\n",
    "\n",
    "    def draw_graph(self):\n",
    "        \"\"\"\n",
    "        グラフを書くだけ\n",
    "        Parameters\n",
    "        ----------\n",
    "        Returns\n",
    "        ----------\n",
    "        \"\"\"\n",
    "        X_line = list(range(0,self.iter,1))\n",
    "\n",
    "        plt.plot(X_line, self.val_loss)\n",
    "        plt.plot(X_line, self.loss)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def MSE(error):\n",
    "    \"\"\"\n",
    "    平均二乗誤差の計算\n",
    "    Parameters\n",
    "    ----------\n",
    "    error : 次の形のndarray, shape (n_samples, 1)\n",
    "      推定した値 - 正解値\n",
    "    Returns\n",
    "    ----------\n",
    "    mse : numpy.float\n",
    "      平均二乗誤差\n",
    "    \"\"\"\n",
    "    for i in range(len(error)):\n",
    "        if i == 0:\n",
    "            mse = error[i] ** 2\n",
    "        else:\n",
    "            mse += (error[i] ** 2)\n",
    "    mse = 1 / len(error) * mse\n",
    "\n",
    "    return mse\n",
    "\n",
    "\n",
    "\n",
    "# ファイル名（パス）を指定する\n",
    "csv_path = \"E:/DiveIntoCode/source/train.csv\" # 絶対パス\n",
    "\n",
    "# 指数表示の禁止を設定する\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# csvファイル読み込み\n",
    "df_train = pd.read_csv(csv_path)\n",
    "\n",
    "# Xに説明変数、yに目的変数となる列をそれぞれ抽出して代入\n",
    "# df_X = df_train[[\"GrLivArea\",\"YearBuilt\"]]\n",
    "# df_y = df_train[\"SalePrice\"]\n",
    "df_X = df_train.loc[0:299,[\"GrLivArea\",\"YearBuilt\"]]\n",
    "df_y = df_train.loc[0:299,[\"SalePrice\"]]\n",
    "# print(df_X, df_y)\n",
    "# X,yをndarrayへ変換\n",
    "X = df_X.values\n",
    "y = df_y.values\n",
    "\n",
    "# 検証用データとテスト用データに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, shuffle=False)\n",
    "\n",
    "# # 標準化しないで進める？\n",
    "# # インスタンス化\n",
    "# scaler = StandardScaler()\n",
    "# # 訓練用のデータのみを.fitで標準化\n",
    "# fit_X_tarin = scaler.fit(X_train)\n",
    "# # 訓練用、検証用双方のデータにtransformで標準化\n",
    "# tr_X_tarin = scaler.transform(X_train)\n",
    "# tr_X_test = scaler.transform(X_test)\n",
    "\n",
    "# 線形回帰による学習\n",
    "# ハイパーパラメータの設定\n",
    "num_iter = 10 # イテレーション数\n",
    "lr = 0.05 # 学習率\n",
    "\n",
    "slr = ScratchLinearRegression(num_iter, lr)\n",
    "slr.fit(X_train, y_train)\n",
    "\n",
    "# # 学習モデルによる推定\n",
    "# Y_pred = slr.predict(X)\n",
    "\n",
    "# # 学習率をグラフ化\n",
    "slr.draw_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc69ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

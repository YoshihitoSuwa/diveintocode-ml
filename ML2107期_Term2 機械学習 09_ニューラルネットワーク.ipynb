{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f4d23aa",
   "metadata": {},
   "source": [
    "## 1.このSprintについて\n",
    "### Sprintの目的\n",
    "　・スクラッチを通してニューラルネットワークの基礎を理解する<br>\n",
    "　・画像データの扱い方を知る<br>\n",
    "### どのように学ぶか\n",
    "　スクラッチで単純なニューラルネットワークを実装した後、学習と検証を行なっていきます。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29a6390",
   "metadata": {},
   "source": [
    "## 2.MNISTデータセット\n",
    "ニューラルネットワークスクラッチの検証にはMNISTデータセットを使用します。各種ライブラリやサイトからダウンロードできますが、ここでは深層学習フレームワークのKerasを用います。以下のコードを実行すればデータセットをダウンロードし、展開まで行えます。<br>\n",
    "### 《データセットをダウンロードするコード》\n",
    "\n",
    "```\n",
    " from keras.datasets import mnist\n",
    " (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "```\n",
    "\n",
    "### 《MNISTとは？》\n",
    "画像分類のための定番データセットで、手書き数字認識を行います。このデータセットには訓練用6万枚、テスト用1万枚の28×28ピクセルの白黒画像、およびそれらが0〜9のどの数字であるかというラベルが含まれています。<br>\n",
    "### 《画像データとは？》\n",
    "デジタル画像は点の集合で、これをピクセルと呼びます。一般的に白黒画像であればピクセルには0〜255の値が含まれます。一方、カラー画像であればR（赤）、G（緑）、B（青）それぞれに対応する0〜255の値が含まれます。機械学習をする上では、この0〜255の値一つひとつが特徴量として扱われます。0〜255は符号なしの8ビット整数で表せる範囲になるため、NumPyであれば「uint8」型の変数として保持できます。<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcb9bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dc4ab8",
   "metadata": {},
   "source": [
    "### データセットの確認\n",
    "どういったデータなのかを見てみます。<br>\n",
    "#### 《サンプルコード》\n",
    "\n",
    "``` \n",
    " print(X_train.shape) # (60000, 28, 28)\n",
    " print(X_test.shape) # (10000, 28, 28)\n",
    " print(X_train[0].dtype) # uint8\n",
    " print(X_train[0])\n",
    "``` \n",
    "\n",
    "各データは28×28ピクセルの白黒画像です。<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "659224a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(60000,)\n",
      "(10000,)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape) # (60000, 28, 28)\n",
    "print(X_test.shape) # (10000, 28, 28)\n",
    "print(y_train.shape) # (60000, )\n",
    "print(y_test.shape) # (10000, )\n",
    "print(X_train[0].dtype) # uint8\n",
    "# print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f2f165",
   "metadata": {},
   "source": [
    "### 平滑化\n",
    "(1, 28, 28)の各画像を、(1, 784)に変換します。これまで学んできた機械学習手法や、今回扱う全結合層のみのニューラルネットワークではこの形で扱います。すべてのピクセルが一列になっていることを、 平滑化（flatten） してあるという風に表現します。<br>\n",
    "#### 《サンプルコード》\n",
    "\n",
    "```\n",
    " X_train = X_train.reshape(-1, 784)\n",
    " X_test = X_test.reshape(-1, 784)\n",
    "```\n",
    "\n",
    "#### 《補足》\n",
    "ここまで機械学習を学んでくる中で、特徴量の数を「次元」と呼んできました。その視点ではMNISTは784次元のデータです。一方で、NumPyのshapeが(784,)の状態を1次元配列とも呼びます。画像としての縦横の情報を持つ（28, 28)の状態であれば、2次元配列です。この視点では2次元のデータです。さらに、もしカラー画像であれば(28, 28, 3)ということになり、3次元配列です。先ほどの視点では3次元のデータになります。しかし、白黒でもカラーでも平面画像であり、立体データではないという視点で、2次元のデータです。画像データを扱う際にはこのように「次元」という言葉が複数の意味合いで使われることに注意してください。<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e888977c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3662fc8",
   "metadata": {},
   "source": [
    "### 画像データの可視化\n",
    "画像データを可視化します。` plt.imshow`に渡します。<br>\n",
    "#### 《サンプルコード》\n",
    "\n",
    "```\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "index = 0\n",
    "image = X_train[index].reshape(28,28)\n",
    "# X_train[index]: (784,)\n",
    "# image: (28, 28)\n",
    "plt.imshow(image, 'gray')\n",
    "plt.title('label : {}'.format(y_train[index]))\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "<a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html\">numpy.reshape — NumPy v1.17 Manual</a><br>\n",
    "<a href=\"https://matplotlib.org/api/_as_gen/matplotlib.pyplot.imshow.html\">matplotlib.pyplot.imshow — Matplotlib 3.1.1 documentation</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a88842cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "index = 0\n",
    "image = X_train[index].reshape(28,28)\n",
    "# X_train[index]: (784,)\n",
    "# image: (28, 28)\n",
    "plt.imshow(image, 'gray')\n",
    "plt.title('label : {}'.format(y_train[index]))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048b8232",
   "metadata": {},
   "source": [
    "### 《発展的話題》\n",
    "画像データは符号なし8ビット整数のuint8型で保持されることが一般的ですが、`plt.imshow`はより自由な配列を画像として表示することが可能です。例えば、以下のようにマイナスの値を持ったfloat64型の浮動小数点であってもエラーにはならないし、先ほどとまったく同じ風に表示されます。<br>\n",
    "\n",
    "```\n",
    "index = 0\n",
    "image = X_train[index].reshape(28,28)\n",
    "image = image.astype(np.float) # float型に変換\n",
    "image -= 105.35 # 意図的に負の小数値を作り出してみる\n",
    "plt.imshow(image, 'gray')\n",
    "plt.title('label : {}'.format(y_train[index]))\n",
    "plt.show()\n",
    "print(image) # 値を確認\n",
    "```\n",
    "\n",
    "これは、自動的に値を0〜255の整数に変換して処理するように作られているからです。uint8型であっても最小値が0、最大値が255でない場合には色合いがおかしくなります。それを防ぐためには次のように引数を入れてください。<br>\n",
    "\n",
    "```\n",
    "plt.imshow(image, 'gray', vmin = 0, vmax = 255)\n",
    "```\n",
    "\n",
    "画像関係のライブラリではこの自動的なスケーリングが思わぬ結果を生むことがあるので、新しいメソッドを使うときには確認しておきましょう。<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2fbe8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -102.35  -87.35  -87.35  -87.35   20.65   30.65\n",
      "    69.65  -79.35   60.65  149.65  141.65   21.65 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -75.35\n",
      "   -69.35  -11.35   48.65   64.65  147.65  147.65  147.65  147.65  147.65\n",
      "   119.65   66.65  147.65  136.65   89.65  -41.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -56.35  132.65\n",
      "   147.65  147.65  147.65  147.65  147.65  147.65  147.65  147.65  145.65\n",
      "   -12.35  -23.35  -23.35  -49.35  -66.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35  113.65\n",
      "   147.65  147.65  147.65  147.65  147.65   92.65   76.65  141.65  135.65\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -25.35\n",
      "    50.65    1.65  147.65  147.65   99.65  -94.35 -105.35  -62.35   48.65\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "   -91.35 -104.35   48.65  147.65  -15.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35   33.65  147.65   84.65 -103.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35  -94.35   84.65  147.65  -35.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35  -70.35  135.65  119.65   54.65    2.65 -104.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35  -24.35  134.65  147.65  147.65   13.65\n",
      "   -80.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35  -60.35   80.65  147.65  147.65\n",
      "    44.65  -78.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -89.35  -12.35  146.65\n",
      "   147.65   81.65 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  143.65\n",
      "   147.65  143.65  -41.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35  -59.35   24.65   77.65  147.65\n",
      "   147.65  101.65 -103.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35  -66.35   42.65  123.65  147.65  147.65  147.65\n",
      "   144.65   76.65 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35  -81.35    8.65  115.65  147.65  147.65  147.65  147.65   95.65\n",
      "   -27.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -82.35\n",
      "   -39.35  107.65  147.65  147.65  147.65  147.65   92.65  -24.35 -103.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35   65.65  113.65\n",
      "   147.65  147.65  147.65  147.65   89.65  -25.35  -96.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35  -50.35   66.65  120.65  147.65  147.65\n",
      "   147.65  147.65  138.65   27.65  -94.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35   30.65  147.65  147.65  147.65  106.65\n",
      "    29.65   26.65  -89.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]]\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np # ← np.float ⇒　float にしたため、コメントアウト\n",
    "\n",
    "index = 0\n",
    "image = X_train[index].reshape(28,28)\n",
    "image = image.astype(float) # float型に変換  ← np.floatは警告が表示される。そのため、「np.float」⇒「float」へ変換\n",
    "image -= 105.35 # 意図的に負の小数値を作り出してみる\n",
    "\n",
    "plt.imshow(image, 'gray')\n",
    "# plt.imshow(image, 'gray', vmin = 0, vmax = 255) # ← 真っ暗な画面になるが？\n",
    "\n",
    "plt.title('label : {}'.format(y_train[index]))\n",
    "plt.show()\n",
    "print(image) # 値を確認\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc72368",
   "metadata": {},
   "source": [
    "### 前処理\n",
    "画像は0から255のuint8型で表されますが、機械学習をする上では0から1のfloat型で扱うことになります。以下のコードで変換可能です。<br>\n",
    "#### 《サンプルコード》\n",
    "\n",
    "```\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max()) # 1.0\n",
    "print(X_train.min()) # 0.0\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e73728e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# X_train = X_train.astype(np.float)\n",
    "# X_test = X_test.astype(np.float)\n",
    "X_train = X_train.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max()) # 1.0\n",
    "print(X_train.min()) # 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cee9bc",
   "metadata": {},
   "source": [
    "また、正解ラベルは0から9の整数ですが、ニューラルネットワークで多クラス分類を行う際には one-hot表現 に変換します。scikit-learnの`OneHotEncoder`を使用したコードが以下です。このone-hot表現による値はそのラベルである確率を示していることになるため、float型で扱います。<br>\n",
    "#### 《サンプルコード》\n",
    "\n",
    "```\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "print(y_train.shape) # (60000,)\n",
    "print(y_train_one_hot.shape) # (60000, 10)\n",
    "print(y_train_one_hot.dtype) # float64\n",
    "```\n",
    "\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">sklearn.preprocessing.OneHotEncoder — scikit-learn 0.21.3 documentation</a><br>\n",
    "<br>\n",
    "さらに、訓練データ6万枚の内2割を検証データとして分割してください。訓練データが48000枚、検証データが12000枚となります。<br>\n",
    "#### 《サンプルコード》\n",
    "\n",
    "```\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "print(X_train.shape) # (48000, 784)\n",
    "print(X_val.shape) # (12000, 784)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04f3ab15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000, 10)\n",
      "float64\n",
      "==================================================\n",
      "(48000, 784)\n",
      "(12000, 784)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "print(y_train.shape) # (60000,)\n",
    "print(y_train_one_hot.shape) # (60000, 10)\n",
    "print(y_train_one_hot.dtype) # float64\n",
    "\n",
    "print(\"==================================================\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "print(X_train.shape) # (48000, 784)\n",
    "print(X_val.shape) # (12000, 784)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ccadfa",
   "metadata": {},
   "source": [
    "## 3.ニューラルネットワークスクラッチ\n",
    "ニューラルネットワークのクラスをスクラッチで作成していきます。NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。<br>\n",
    "<br>\n",
    "今回は多クラス分類を行う3層のニューラルネットワークを作成します。層の数などは固定した上でニューラルネットワークの基本を学びます。次のSprintで層を自由に変えられる設計にしていきます。<br>\n",
    "<br>\n",
    "以下に雛形を用意してあります。このScratchSimpleNeuralNetrowkClassifierクラスにコードを書き加えていってください。<br>\n",
    "\n",
    "#### 《雛形》\n",
    "\n",
    "```\n",
    "class ScratchSimpleNeuralNetrowkClassifier():\n",
    "    \"\"\"\n",
    "    シンプルな三層ニューラルネットワーク分類器\n",
    "    Parameters\n",
    "    ----------\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose = True):\n",
    "        self.verbose = verbose\n",
    "        pass\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程などを出力する\n",
    "            print()\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        pass\n",
    "        return\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a02cf7",
   "metadata": {},
   "source": [
    "### ミニバッチ処理\n",
    "これまでの機械学習スクラッチでは、すべてのサンプルを一度に計算していました。しかし、ニューラルネットワークではデータを分割して入力する 確率的勾配降下法 が一般的です。分割した際のひとかたまりを ミニバッチ 、そのサンプル数を バッチサイズ と呼びます。<br>\n",
    "<br>\n",
    "今回はバッチサイズを20とします。今回使う訓練データは48000枚ですから、48000÷20で2400回の更新を繰り返すことになります。ニューラルネットワークではこれを2400回 イテレーション（iteration） すると呼びます。訓練データを一度すべて見ると1回の エポック（epoch） が終わったことになります。このエポックを複数回繰り返し、学習が完了します。<br>\n",
    "<br>\n",
    "これを実現するための簡素なイテレータを用意しました。for文で呼び出すと、ミニバッチを取得できます。<br>\n",
    "\n",
    "#### 《コード》\n",
    "\n",
    "```\n",
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b9e416",
   "metadata": {},
   "source": [
    "このクラスをインスタンス化し、for文を使うことでミニバッチが取り出せます。\n",
    "\n",
    "```\n",
    "get_mini_batch = GetMiniBatch(X_train, y_train, batch_size=20)\n",
    "print(len(get_mini_batch)) # 2400\n",
    "print(get_mini_batch[5]) # 5番目のミニバッチが取得できる\n",
    "for mini_X_train, mini_y_train in get_mini_batch:\n",
    "    # このfor文内でミニバッチが使える\n",
    "    pass\n",
    "```\n",
    "\n",
    "`__getitem__` や `__next__` は `__init__` と同じ特殊メソッドの一種です。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569b7c0d",
   "metadata": {},
   "source": [
    "### 学習\n",
    "ニューラルネットワークの学習はフォワードプロパゲーションとバックプロパゲションの繰り返しになります。<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2af0c2b",
   "metadata": {},
   "source": [
    "### 【問題1】重みの初期値を決めるコードの作成\n",
    "ニューラルネットワークの各層の重みの初期値を決めるコードを作成してください。<br>\n",
    "<br>\n",
    "重みの初期値はさまざまな方法が提案されていますが、今回はガウス分布による単純な初期化を行います。バイアスに関しても同様です。<br>\n",
    "<br>\n",
    "以下のコードを参考にしてください。標準偏差の値sigmaはハイパーパラメータです。発展的な重みの初期化方法については次のSprintで扱います。<br>\n",
    "\n",
    "#### 《サンプルコード》\n",
    "\n",
    "```\n",
    "n_features = 784\n",
    "n_nodes1 = 400\n",
    "sigma = 0.01 # ガウス分布の標準偏差\n",
    "W1 = sigma * np.random.randn(n_features, n_nodes1)\n",
    "# W1: (784, 400)\n",
    "```\n",
    "\n",
    "<a href=\"https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.randn.html\">numpy.random.randn — NumPy v1.15 Manual</a><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9309fbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAASh0lEQVR4nO3dbYxc53ne8f9V0pYrMabEMtqyolCqBptEDlraXqhSXRRLKLYFRRD1wQZo1AGRqCAMuKn6IrhS9cGfBDtxWzsFahREZJiBFbOq4kCE0yRmWU2NApQcUZZfJFoWbTUyLUqMTVvR0gVTKnc/7GyxoZba3Tnzsvvs/wcMZs5zXp775sxePDw7M0xVIUlqy1+bdAGSpOEz3CWpQYa7JDXIcJekBhnuktSgjZMuAGDr1q21Y8eOSZexYufOneOKK66YdBljZc/rw3rrea32e/z48R9W1c8utm5VhPuOHTt44oknJl3GivV6PWZmZiZdxljZ8/qw3npeq/0m+dNLrfOyjCQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNWhVfEJVWtKjH5/c3LlpcnNLA/LMXZIa5Jm71oRj3/vR5CZ/2+SmlgblmbskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBi0Z7kk+m+RMkm8tsu7uJJVk64Kxe5OcTPJskvcNu2BJ0tKWc+b+OeCWiweTXAu8B3hhwdj1wF7g7f19PpNkw1AqlSQt25LhXlVfAc4usupTwEeBWjC2BzhUVeer6nngJHDDMAqVJC3fQN8KmeR24AdV9fUkC1ddAzy2YPlUf2yxY+wH9gNMTU3R6/UGKWWiZmdn12TdXUyq53Obd419znnl89y8FvtdcbgnuRy4D3jvYqsXGatFxqiqA8ABgOnp6ZqZmVlpKRPX6/VYi3V3Mamejz1w99jnnHd+620+z41rsd9BztzfBlwHzJ+1bweeTHIDc2fq1y7YdjvwYtciJUkrs+K3QlbVN6vq6qraUVU7mAv0d1bVS8BhYG+Sy5JcB+wEvjrUiiVJS1rOWyG/ABwDfi7JqSR3XmrbqnoaeAh4Bvgj4CNV9dqwipUkLc+Sl2Wq6oNLrN9x0fL9wP3dypIkdeEnVCWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwb6P1SldeXVl+DRj49/3t33jn9ONcMzd0lqkOEuSQ0y3CWpQcv5P1Q/m+RMkm8tGPtkkm8n+UaS309y5YJ19yY5meTZJO8bUd2SpDewnDP3zwG3XDR2BPjFqvp7wHeAewGSXA/sBd7e3+czSTYMrVpJ0rIsGe5V9RXg7EVjX66qC/3Fx4Dt/cd7gENVdb6qngdOAjcMsV5J0jIM462Qvwb8l/7ja5gL+3mn+mOvk2Q/sB9gamqKXq83hFLGa3Z2dk3W3cWkej63edfY55xXf3kZvdnrxj/xBF9b6+213WK/ncI9yX3ABeDB+aFFNqvF9q2qA8ABgOnp6ZqZmelSykT0ej3WYt1dTKrnYw/cPfY5552/epqZTc+Pf+KZveOfs2+9vbZb7HfgcE+yD7gNuLmq5gP8FHDtgs22Ay8OXp4kaRADvRUyyS3AvwFur6qfLlh1GNib5LIk1wE7ga92L1OStBJLnrkn+QIwA2xNcgr4GHPvjrkMOJIE4LGq+nBVPZ3kIeAZ5i7XfKSqXhtV8ZKkxS0Z7lX1wUWGH3iD7e8H7u9SlCSpG784TFrCufMXOHbmR2Of96bdY59SDfHrBySpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBS4Z7ks8mOZPkWwvGtiQ5kuS5/v1VC9bdm+RkkmeTvG9UhUuSLm05Z+6fA265aOwe4GhV7QSO9pdJcj2wF3h7f5/PJNkwtGolScuyZLhX1VeAsxcN7wEO9h8fBO5YMH6oqs5X1fPASeCG4ZQqSVquQa+5T1XVaYD+/dX98WuA7y/Y7lR/TJI0RhuHfLwsMlaLbpjsB/YDTE1N0ev1hlzK6M3Ozq7JuruYVM/nNu8a+5zzLmy4nLMTmH+Sr6319tpusd9Bw/3lJNuq6nSSbcCZ/vgp4NoF220HXlzsAFV1ADgAMD09XTMzMwOWMjm9Xo+1WHcXk+r52AN3j33OeWc372LLK0+Nfd6b3v+hsc85b729tlvsd9DLMoeBff3H+4BHFozvTXJZkuuAncBXu5UoSVqpJc/ck3wBmAG2JjkFfAz4BPBQkjuBF4APAFTV00keAp4BLgAfqarXRlS7JOkSlgz3qvrgJVbdfInt7wfu71KUJKkbP6EqSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNahTuCf5l0meTvKtJF9I8pYkW5IcSfJc//6qYRUrSVqegcM9yTXAPwemq+oXgQ3AXuAe4GhV7QSO9pclSWPU9bLMRuCvJ9kIXA68COwBDvbXHwTu6DiHJGmFUlWD75zcBdwP/B/gy1X1T5L8pKquXLDNj6vqdZdmkuwH9gNMTU2969ChQwPXMSmzs7Ns2rRp0mWM1aR6PvfDU2Ofc96FDZez8bWfjn3eK7ZuH/uc89bba3ut9rt79+7jVTW92LqNgx60fy19D3Ad8BPgvyb50HL3r6oDwAGA6enpmpmZGbSUien1eqzFuruYVM/HHrh77HPOO7t5F1teeWrs8970/mX/OA3denttt9hvl8syvwQ8X1V/VlX/F/gi8A+Bl5NsA+jfn+lepiRpJbqE+wvAjUkuTxLgZuAEcBjY199mH/BItxIlSSs18GWZqno8ycPAk8AF4GvMXWbZBDyU5E7m/gL4wDAKlSQt38DhDlBVHwM+dtHweebO4iVJE+InVCWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNahTuCe5MsnDSb6d5ESSm5JsSXIkyXP9+6uGVawkaXm6nrn/FvBHVfXzwN8HTgD3AEeraidwtL8sSRqjgcM9yVuBfww8AFBVf1FVPwH2AAf7mx0E7uhWoiRppVJVg+2Y7AIOAM8wd9Z+HLgL+EFVXblgux9X1esuzSTZD+wHmJqaetehQ4cGqmOSZmdn2bRp06TLGKtJ9Xzuh6fGPue8CxsuZ+NrPx37vFds3T72Oeett9f2Wu139+7dx6tqerF1XcJ9GngMeHdVPZ7kt4A/B359OeG+0PT0dD3xxBMD1TFJvV6PmZmZSZcxVpPq+dgDd499znlnN+9iyytPjX3em+78d2Ofc956e22v1X6TXDLcu1xzPwWcqqrH+8sPA+8EXk6yrT/xNuBMhzkkSQMYONyr6iXg+0l+rj90M3OXaA4D+/pj+4BHOlUoSVqxjR33/3XgwSRvBr4H/Cpzf2E8lORO4AXgAx3nkCStUKdwr6qngMWu99zc5biSpG78hKokNajrZRmtM2dePc+njnxn7PPeOPYZJ28Sf87z3vGmiU2tIfHMXZIaZLhLUoO8LKMVueL8n3HjmSOTLkPSEjxzl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQb7PXVqlbnzhwMTmPv+22yY2t4bDM3dJapDhLkkNMtwlqUGGuyQ1yHCXpAZ1DvckG5J8LcmX+stbkhxJ8lz//qruZUqSVmIYZ+53AScWLN8DHK2qncDR/rIkaYw6hXuS7cAvA7+9YHgPcLD/+CBwR5c5JEkr1/VDTJ8GPgr8zIKxqao6DVBVp5NcvdiOSfYD+wGmpqbo9XodSxm/2dnZNVl3Fxc2XM7ZzbsmXcZYrceea529tlv8WR443JPcBpypquNJZla6f1UdAA4ATE9P18zMig8xcb1ej7VYdxd/8PDn2fLKU5MuY6zObt617no+v/W2dfXabvFnucuZ+7uB25PcCrwFeGuSzwMvJ9nWP2vfBpwZRqGSpOUb+Jp7Vd1bVduragewF/gfVfUh4DCwr7/ZPuCRzlVKklZkFO9z/wTwniTPAe/pL0uSxmgo3wpZVT2g13/8I+DmYRxXkjQYP6EqSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBA4d7kmuTPJrkRJKnk9zVH9+S5EiS5/r3Vw2vXEnScnQ5c78A/Ouq+gXgRuAjSa4H7gGOVtVO4Gh/WZI0RgOHe1Wdrqon+49fBU4A1wB7gIP9zQ4Cd3SsUZK0QkO55p5kB/AO4HFgqqpOw9xfAMDVw5hDkrR8qapuB0g2Af8TuL+qvpjkJ1V15YL1P66q1113T7If2A8wNTX1rkOHDnWqYxJmZ2fZtGnTpMsYq1d+fJaNr/100mWM1YUNl6+7nustV66r1/Za/VnevXv38aqaXmzdxi4HTvIm4PeAB6vqi/3hl5Nsq6rTSbYBZxbbt6oOAAcApqena2ZmpkspE9Hr9ViLdXfxBw9/ni2vPDXpMsbq7OZd667n81tvW1ev7RZ/lru8WybAA8CJqvoPC1YdBvb1H+8DHhm8PEnSILqcub8b+BXgm0me6o/9W+ATwENJ7gReAD7QqUJJ0ooNHO5V9b+AXGL1zYMeV5LUnZ9QlaQGGe6S1CDDXZIa1OmtkJIa9epL8OjHxz/v7nvHP2ejDPc16FNHvjOxuf/uxGaWtBJelpGkBhnuktQgw12SGuQ1d0mvc+78BY6d+dHY571p99inbJZn7pLUIM/c16AbXzgwsbnPbt41sbklLZ9n7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGjSzck9yS5NkkJ5PcM6p5JEmvN5JPqCbZAPwn4D3AKeBPkhyuqmdGMd+knHn1/ES+W/3Gsc8oaa0Z1Zn7DcDJqvpeVf0FcAjYM6K5JEkXGdV3y1wDfH/B8ingHyzcIMl+YH9/cTbJsyOqZZS2Aj+cdBFjZs/rw2R6/qf/fuxT9q3V5/hvX2rFqMI9i4zVX1moOgBM7huwhiDJE1U1Pek6xsme14f11nOL/Y7qsswp4NoFy9uBF0c0lyTpIqMK9z8Bdia5Lsmbgb3A4RHNJUm6yEguy1TVhST/DPhjYAPw2ap6ehRzTdiavqw0IHteH9Zbz831m6paeitJ0priJ1QlqUGGuyQ1yHBfQpItSY4kea5/f9UltnvDr1tIcneSSrJ19FV307XnJJ9M8u0k30jy+0muHFvxK7CM5yxJ/mN//TeSvHO5+65Wg/ac5NokjyY5keTpJHeNv/rBdHme++s3JPlaki+Nr+ohqCpvb3ADfhO4p//4HuA3FtlmA/Bd4O8Abwa+Dly/YP21zP1y+U+BrZPuadQ9A+8FNvYf/8Zi+0/6ttRz1t/mVuAPmfvcxo3A48vddzXeOva8DXhn//HPAN9pvecF6/8V8LvAlybdz0punrkvbQ9wsP/4IHDHItss9XULnwI+ykUf5FrFOvVcVV+uqgv97R5j7nMOq81yviJjD/A7Necx4Mok25a572o0cM9VdbqqngSoqleBE8x9En216/I8k2Q78MvAb4+z6GEw3Jc2VVWnAfr3Vy+yzWJft3ANQJLbgR9U1ddHXegQder5Ir/G3FnRarOc+i+1zXJ7X2269Pz/JdkBvAN4fPglDl3Xnj/N3InZX46ovpEZ1dcPrClJ/jvwNxdZdd9yD7HIWCW5vH+M9w5a26iMqueL5rgPuAA8uLLqxmLJ+t9gm+Xsuxp16XluZbIJ+D3gX1TVnw+xtlEZuOcktwFnqup4kplhFzZqhjtQVb90qXVJXp7/Z2n/n2pnFtnsUl+38DbgOuDrSebHn0xyQ1W9NLQGBjDCnuePsQ+4Dbi5+hcuV5nlfEXGpbZ58zL2XY269EySNzEX7A9W1RdHWOcwden5/cDtSW4F3gK8Ncnnq+pDI6x3eCZ90X+134BP8ld/ufibi2yzEfgec0E+/0ubty+y3f9mbfxCtVPPwC3AM8DPTrqXN+hxyeeMuWutC3/R9tWVPN+r7dax5wC/A3x60n2Mq+eLtplhjf1CdeIFrPYb8DeAo8Bz/fst/fG/Bfy3Bdvdytw7CL4L3HeJY62VcO/UM3CSuWuYT/Vv/3nSPV2iz9fVD3wY+HD/cZj7T2e+C3wTmF7J870ab4P2DPwj5i5nfGPB83rrpPsZ9fO84BhrLtz9+gFJapDvlpGkBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUH/D6fLOtOqfjpHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_features = 784\n",
    "n_nodes1 = 400\n",
    "sigma = 0.01 # ガウス分布の標準偏差\n",
    "W1 = sigma * np.random.randn(n_features, n_nodes1)\n",
    "# W1: (784, 400)\n",
    "\n",
    "plt.grid()\n",
    "plt.hist(W1[0], bins=10, range=[-0.05, 0.05], alpha=0.5)\n",
    "plt.hist(W1[1], bins=10, range=[-0.05, 0.05], alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751b75b5",
   "metadata": {},
   "source": [
    "### 【問題2】フォワードプロパゲーションの実装\n",
    "三層のニューラルネットワークの フォワードプロパゲーション を作成してください。以下の説明ではノード数は1層目は400、2層目は200としますが、変更しても構いません。<br>\n",
    "各層の数式を以下に示します。今回はそれぞれの記号が表す配列が、実装上どのようなndarrayのshapeになるかを併記してあります。<br>\n",
    "\n",
    "```\n",
    "batch_size = 20 # バッチサイズ\n",
    "n_features = 784 # 特徴量の数\n",
    "n_nodes1 = 400 # 1層目のノード数\n",
    "n_nodes2 = 200 # 2層目のノード数\n",
    "n_output = 10 # 出力のクラス数（3層目のノード数）\n",
    "```\n",
    "\n",
    "「1層目」<br>\n",
    "　　$ [ A_1 = X \\cdot W_1 + B_1 ] $<br>\n",
    "　　$ X $ : 特徴量ベクトル (batch_size, n_features)<br>\n",
    "　　$ W_1 $ : 1層目の重み (n_features, n_nodes1)<br>\n",
    "　　$ B_1 $ : 1層目のバイアス (n_nodes1,)<br>\n",
    "　　$ A_1 $ : 出力 (batch_size, n_nodes1)<br>\n",
    "<br>\n",
    "「1層目の活性化関数」<br>\n",
    "　　$ [ Z_1 = f(A_1) ] $<br>\n",
    "　　$ f() $ : 活性化関数<br>\n",
    "　　$ Z_1 $ : 出力 (batch_size, n_nodes1)<br>\n",
    "<br>\n",
    "「2層目」<br>\n",
    "　　$ [ A_2 = Z_1 \\cdot W_2 + B_2 ] $<br>\n",
    "　　$ W_2 $ : 2層目の重み (n_nodes1, n_nodes2)<br>\n",
    "　　$ B_2 $ : 2層目のバイアス (n_nodes2,)<br>\n",
    "　　$ A_2 $ : 出力 (batch_size, n_nodes2)<br>\n",
    "<br>\n",
    "「2層目の活性化関数」<br>\n",
    "　　$ [ Z_2 = f(A_2) ] $<br>\n",
    "　　$ f() $ : 活性化関数<br>\n",
    "　　$ Z_2 $ : 出力 (batch_size, n_nodes2)<br>\n",
    "<br>\n",
    "「3層目（出力層）」<br>\n",
    "　　$ [ A_3 = Z_2 \\cdot W_3 + B_3 ] $<br>\n",
    "　　$ W_3 $ : 3層目の重み (n_nodes2, n_output)<br>\n",
    "　　$ B_3 $ : 3層目のバイアス (n_output,)<br>\n",
    "　　$ A_3 $ : 出力 (batch_size, n_output)<br>\n",
    "<br>\n",
    "「3層目の活性化関数」<br>\n",
    "　　$ [ Z_3 = softmax(A_3) ] $<br>\n",
    "　　$ softmax() $ : ソフトマックス関数<br>\n",
    "　　$ Z_3 $ : 出力 (batch_size, n_output)<br>\n",
    "　　$ Z_3 $ : は各ラベル（0〜9）に対する確率の配列である。<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaeaff2",
   "metadata": {},
   "source": [
    "### 活性化関数（フォワードプロバゲーション）\n",
    "活性化関数を作成し、フォワードプロパゲーションの中で使用します。切り替えられるように実装することを推奨しますが、片方でも構いません。<br>\n",
    "「シグモイド関数」<br>\n",
    "\n",
    " $ [ f(Z) = sigmoid(A) = \\frac{1}{1+exp(-A)} ] $<br>\n",
    "\n",
    "指数関数 $ exp(-A) $ の計算は `numpy.exp` を使用してください。<br>\n",
    "<a href=\"https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.exp.html\">numpy.exp — NumPy v1.15 Manual</a><br>\n",
    "<br>\n",
    "「ハイパボリックタンジェント関数」<br>\n",
    "次の数式で表されますが、 `numpy.tanh` ひとつで実現できます。<br>\n",
    "\n",
    " $ [ f(Z) = \\tanh(A) = \\frac{exp(A) - exp(-A)}{exp(A) + exp(-A)} ] $<br>\n",
    "\n",
    "<a href=\"https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.tanh.html\">numpy.tanh — NumPy v1.15 Manual</a><br>\n",
    "＊現在ではこれらの代わりにReLUと呼ばれる活性化関数が一般的です。次のSprintで扱います。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe9928c",
   "metadata": {},
   "source": [
    "### ソフトマックス関数\n",
    "ソフトマックス関数を作成し、フォワードプロパゲーションの中で使用します。これも活性化関数の一種ですが、多クラス分類の出力層で使われる特性上、区別して扱われることが多いです。<br>\n",
    "次の数式です。<br>\n",
    "\n",
    " $ [ Z_{3\\_k} = \\frac{exp(A_{3\\_k})}{\\sum_{i=1}^{n_c}exp(A_{3\\_i})} ] $ <br>\n",
    "\n",
    "$ Z_{3_k} $ : $ k $ 番目のクラスの確率ベクトル (batch_size,)<br>\n",
    "$ A_{3_k} $ : $ k $ 番目のクラスにあたる前の層からのベクトル (batch_size,)<br>\n",
    "$ n_c $ : クラスの数、(n_output。今回のMNISTでは10。<br>\n",
    "\n",
    "分母はすべてのクラスに相当する値を指数関数に通した上で足し合わせたものです。その中で、分子に $k$ 番目のクラスを持ってくることで、 $k$ 番目のクラスである確率が求まります。<br>\n",
    "<br>\n",
    "これを10クラス分計算し、合わせたものが $Z_3$ です。<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcb2e8a",
   "metadata": {},
   "source": [
    "### 【問題3】交差エントロピー誤差の実装\n",
    "目的関数（損失関数）を作成します。<br>\n",
    "多クラス分類の目的関数である交差エントロピー誤差 $ L $ は次の数式です。<br>\n",
    "\n",
    "　　　　$ L = - \\frac{1}{n_b}\\displaystyle\\sum_{j}^{n_b}\\sum_{k}^{n_c}y_{jk} log(z_{3\\_jk}) $ <br>\n",
    "\n",
    "　　$ y_{ij} $ : $ j $ 番目のサンプルの $ k $ 番目のクラスの正解ラベル (one-hot表現で0か1のスカラー)<br>\n",
    "　　$ z_{3ij} $ : $ j $ 番目のサンプルの $ k $ 番目のクラスの確率 (スカラー)<br>\n",
    "　　$ n_b $ : バッチサイズ (batch_size, )<br>\n",
    "　　$ n_c $ : クラスの数（今回のMNISTでは10） (n_output, )<br>\n",
    "<br>\n",
    "サンプル1つあたりの誤差が求まります。<br>\n",
    "実数における $ log(x) $ の定義域は ` 0 < x ` です。したがって、logの中身がとても小さい値になってしまったときエラーを起こします。そこでlogの中に1e-7を足すことでエラーを回避できます。<br>\n",
    "こういった処理はlogに限らず、さまざまな場所で出てくることがあります。<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c65370",
   "metadata": {},
   "source": [
    "### 【問題4】バックプロパゲーションの実装\n",
    "三層のニューラルネットワークのバックプロパゲーションを作成してください。確率的勾配降下法を行う部分です。<br>\n",
    "数式を以下に示します。<br>\n",
    "まず、i層目の重みとバイアスの更新式です。 $ W_i $ と $ B_i $ に対し、更新後の $ W'_i $ と $ B'_i $ は次の数式で求められます。<br>\n",
    "\n",
    "　　　　$ W_i^{\\prime} = W_i - \\alpha \\displaystyle\\frac{\\partial L}{\\partial W_i} $<br>\n",
    "\n",
    "　　　　$ B_i^{\\prime} = B_i - \\alpha \\displaystyle\\frac{\\partial L}{\\partial B_i} $<br>\n",
    "\n",
    "　　　　$ \\alpha $ : 学習率（層ごとに変えることも可能だが、基本的にはすべて同じとする）<br>\n",
    "　　　　$ \\frac{\\partial L}{\\partial W_i} $ : $ W_i $ に関する損失 $ L $ の勾配<br>\n",
    "　　　　$ \\frac{\\partial L}{\\partial B_i} $ : $ B_i $ に関する損失 $ L $ の勾配<br>\n",
    "　　　　　　＊この勾配はミニバッチのサンプル数分の合計または平均を考えます。ここでは合計を計算します。<br>\n",
    "<br>\n",
    "この更新方法はSprint3線形回帰やsprint4ロジスティック回帰における最急降下法と同様です。より効果的な更新方法が知られており、それは次のSprintで扱います。<br>\n",
    "<br>\n",
    "勾配 $ \\frac{\\partial L}{\\partial W_i} $ : $ W_i $ や $ \\frac{\\partial L}{\\partial B_i} $ : $ B_i $ を求めるために、バックプロパゲーションを行います。以下の数式です。ハイパボリックタンジェント関数を使用した例を載せました。シグモイド関数の場合の数式はその後ろにあります。<br>\n",
    "\n",
    "　「3層目」<br>\n",
    "\n",
    "　　　　$ \\displaystyle\\frac{\\partial L}{\\partial A_3} = \\frac{1}{n_b}(Z_{3} - Y) $<br>\n",
    "　　　　$ \\displaystyle\\frac{\\partial L}{\\partial B_3} = \\sum_{j}^{n_b}\\frac{\\partial L}{\\partial A_{3\\_j}} $<br>\n",
    "　　　　$ \\displaystyle\\frac{\\partial L}{\\partial W_3} = Z_{2}^{T}\\cdot \\frac{\\partial L}{\\partial A_3} $<br>\n",
    "　　　　$ \\displaystyle\\frac{\\partial L}{\\partial Z_2} = \\frac{\\partial L}{\\partial A_3} \\cdot W_3^T $<br>\n",
    "<br>\n",
    "　　　　$ \\frac{\\partial L}{\\partial A_3} $ : $ A_3 $ に関する損失 $ L $ の勾配 (batch_size, n_output)<br>\n",
    "　　　　$ \\frac{\\partial L}{\\partial A_{3j}} $ : $ j $ 番目のサンプルの $ A_3 $ に関する損失 $ L $ の勾配 (n_nodes2, )<br>\n",
    "　　　　$ \\frac{\\partial L}{\\partial B_3} $ : $ B_3 $ に関する損失 $ L $ の勾配 (n_output, )<br>\n",
    "　　　　$ \\frac{\\partial L}{\\partial W_3} $ : $ W_3 $ に関する損失 $ L $ の勾配 (n_nodes2, n_output)<br>\n",
    "　　　　$ \\frac{\\partial L}{\\partial Z_2} $ : $ Z_2 $ に関する損失 $ L $ の勾配 (batch_size, n_nodes2)<br>\n",
    "　　　　$ Z_3 $ : ソフトマックス関数の出力 (batch_size, n_nodes2)<br>\n",
    "　　　　$ Y $ : 正解ラベル (batch_size, n_output)<br>\n",
    "　　　　$ Z_2 $ : 2層目の活性化関数の出力 (batch_size, n_nodes2)<br>\n",
    "　　　　$ W_3 $ : 3層目の重み (n_nodes2, n_output)<br>\n",
    "　　　　$ n_b $ : バッチサイズ (batch_size, )<br>\n",
    "<br>\n",
    "\n",
    "　「2層目」<br>\n",
    "\n",
    "　　　　$ \\displaystyle\\frac{\\partial L}{\\partial A_2} = \\frac{\\partial L}{\\partial Z_2} \\odot \\{1-tanh^2(A_{2})\\} $<br>\n",
    "　　　　$ \\displaystyle\\frac{\\partial L}{\\partial B_2} = \\sum_{j}^{n_b}\\frac{\\partial L}{\\partial A_{2\\_j}} $<br>\n",
    "　　　　$ \\displaystyle\\frac{\\partial L}{\\partial W_2} = Z_{1}^T \\cdot \\frac{\\partial L}{\\partial A_2} $<br>\n",
    "　　　　$ \\displaystyle\\frac{\\partial L}{\\partial Z_1} = \\frac{\\partial L}{\\partial A_2} \\cdot W_2^T $<br>\n",
    "<br>\n",
    "　　　　$ \\frac{\\partial L}{\\partial A_2} $ : $ A_2 $ に関する損失 $ L $ の勾配 (batch_size, n_nodes2)<br>\n",
    "　　　　$ \\frac{\\partial L}{\\partial A_{2j}} $ : $ j $ 番目のサンプルの $ A_2 $ に関する損失 $ L $ の勾配 (n_nodes2, )<br>\n",
    "　　　　$ \\frac{\\partial L}{\\partial B_2} $ : $ B_2 $ に関する損失 $ L $ の勾配 (n_nodes2, )<br>\n",
    "　　　　$ \\frac{\\partial L}{\\partial W_2} $ : $ W_2 $ に関する損失 $ L $ の勾配 (n_nodes1, n_nodes2)<br>\n",
    "　　　　$ \\frac{\\partial L}{\\partial Z_2} $ : $ Z_2 $ に関する損失 $ L $ の勾配 (batch_size, n_nodes2)<br>\n",
    "　　　　$ A_2 $ : 2層目の出力 (batch_size, n_nodes2)<br>\n",
    "　　　　$ Z_1 $ : 1層目の活性化関数の出力 (batch_size, n_nodes1)<br>\n",
    "　　　　$ W_2 $ : 2層目の重み (n_nodes1, n_nodes2)<br>\n",
    "<br>\n",
    "\n",
    "　「1層目」<br>\n",
    "\n",
    "　　　　$ \\displaystyle\\frac{\\partial L}{\\partial A_1} = \\frac{\\partial L}{\\partial Z_1} \\odot \\{1-tanh^2(A_{1})\\} $<br>\n",
    "　　　　$ \\displaystyle\\frac{\\partial L}{\\partial B_1} = \\sum_{j}^{n_b}\\frac{\\partial L}{\\partial A_{1\\_j}} $<br>\n",
    "　　　　$ \\displaystyle\\frac{\\partial L}{\\partial W_1} = X^T \\cdot \\frac{\\partial L}{\\partial A_1} $<br>\n",
    "<br>\n",
    "　　　　$ \\frac{\\partial L}{\\partial A_1} $ : $ A_1 $ に関する損失 $ L $ の勾配 (batch_size, n_nodes1)<br>\n",
    "　　　　$ \\frac{\\partial L}{\\partial A_{1j}} $ : $ j $ 番目のサンプルの $ A_1 $ に関する損失 $ L $ の勾配 (n_nodes1, )<br>\n",
    "　　　　$ \\frac{\\partial L}{\\partial B_1} $ : $ B_1 $ に関する損失 $ L $ の勾配 (n_nodes1, )<br>\n",
    "　　　　$ \\frac{\\partial L}{\\partial W_1} $ : $ W_1 $ に関する損失 $ L $ の勾配 (n_features, n_nodes1)<br>\n",
    "　　　　$ \\frac{\\partial L}{\\partial Z_1} $ : $ Z_1 $ に関する損失 $ L $ の勾配 (batch_size, n_nodes1)<br>\n",
    "　　　　$ A_1 $ : 1層目の出力 (batch_size, n_nodes1)<br>\n",
    "　　　　$ X $ : 特徴量ベクトル (batch_size, n_features)<br>\n",
    "　　　　$ W_1 $ : 1層目の重み (n_features, n_nodes1)<br>\n",
    "<br>\n",
    "\n",
    "#### 《補足》\n",
    "活性化関数にシグモイド関数を使用した場合は、次のようになります。<br>\n",
    "\n",
    "　　　　$ \\displaystyle\\frac{\\partial L}{\\partial A_2} = \\frac{\\partial L}{\\partial Z_2} \\odot  \\{1-sigmoid(A_{2})\\}\\odot sigmoid(A_{2})\n",
    " $<br>\n",
    "　　　　$ \\displaystyle\\frac{\\partial L}{\\partial A_1} = \\frac{\\partial L}{\\partial Z_1} \\odot  \\{1-sigmoid(A_{1})\\}\\odot sigmoid(A_{1}) $<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c969ddc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "#         self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4ac9e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "class ScratchSimpleNeuralNetrowkClassifier():\n",
    "    \"\"\"\n",
    "    シンプルな三層ニューラルネットワーク分類器\n",
    "    Parameters\n",
    "    ----------\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma, batch_size, n_features, n_nodes1, n_nodes2, n_output, num_iter=10, alpha=0.0005, verbose = True):\n",
    "        self.sigma = sigma # ガウス分布（正規分布）用の標準偏差\n",
    "        self.batch_size = batch_size # バッチサイズ\n",
    "        self.n_features = n_features # 特徴量の数\n",
    "        self.n_nodes1 = n_nodes1 # 1層目のノード数\n",
    "        self.n_nodes2 = n_nodes2 # 2層目のノード数\n",
    "        self.n_output = n_output # 出力のクラス数（3層目のノード数）\n",
    "        self.num_iter = num_iter # イテレーション回数\n",
    "        self.alpha = alpha # 学習率\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None, fp=\"sigmoid\"):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"特徴量ベクトル(batch_size, n_features)：{}\".format(X.shape))\n",
    "        print(\"バッチサイズ(self.batch_size) : {}\".format(self.batch_size)) # バッチサイズ\n",
    "        print(\"特徴量の数(self.n_features) : {}\".format(self.n_features)) # 特徴量の数\n",
    "        print(\"1層目のノード数(self.n_nodes1) : {}\".format(self.n_nodes1)) # 1層目のノード数\n",
    "        print(\"2層目のノード数(self.n_nodes2) : {}\".format(self.n_nodes2)) # 2層目のノード数\n",
    "        print(\"出力のクラス数（3層目のノード数）(self.n_output): {}\".format(self.n_output)) # 出力のクラス数（3層目のノード数）\n",
    "\n",
    "        self.cee_array = []\n",
    "\n",
    "        for num_iter in range(self.num_iter):\n",
    "\n",
    "            # 重みの初期値（１～３層）\n",
    "            self.w1 = sigma * np.random.randn(self.n_features, self.n_nodes1) # 重み\n",
    "            self.w2 = sigma * np.random.randn(self.n_nodes1, self.n_nodes2) # 重み\n",
    "            self.w3 = sigma * np.random.randn(self.n_nodes2, self.n_output) # 重み\n",
    "\n",
    "            # バイアス項の初期値\n",
    "            self.b1 = self.n_nodes1\n",
    "            self.b2 = self.n_nodes2\n",
    "            self.b3 = self.n_output\n",
    "\n",
    "            # ミニバッチ処理\n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=20)\n",
    "#             print(len(get_mini_batch)) # 2400\n",
    "#             print(get_mini_batch[5]) # 5番目のミニバッチが取得できる\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "\n",
    "                ### フォワードプロバゲーション\n",
    "\n",
    "                ### 1層目\n",
    "#                 print(\"===== フォワードプロバゲーション 1層 =============================================\")\n",
    "#                 w1 = sigma * np.random.randn(self.n_features, self.n_nodes1) # 重み\n",
    "                a1 = mini_X_train @ self.w1 + self.b1 # a1 : 出力 (batch_size, n_nodes1)\n",
    "                if fp == \"sigmoid\": # シグモイド関数\n",
    "                    z1 = 1 / (1 + np.exp(-1 * a1))\n",
    "                else: # ハイパボリックタンジェント関数\n",
    "                    z1 = np.tanh(a1)\n",
    "\n",
    "#                 print(\"z1 : {}、出力 (batch_size, n_nodes1)\".format(z1.shape)) # z1 : 出力 (batch_size, n_nodes1\n",
    "#                 print(w1)\n",
    "#                 print(a1)\n",
    "#                 print(z1)\n",
    "\n",
    "                ### 2層目\n",
    "#                 print(\"===== フォワードプロバゲーション 2層 =============================================\")\n",
    "#                 w2 = sigma * np.random.randn(self.n_nodes1, self.n_nodes2) # 重み\n",
    "                a2 = z1 @ self.w2 + self.b2 # a2 : 出力 (batch_size, n_nodes2)\n",
    "                if fp == \"sigmoid\": # シグモイド関数\n",
    "                    z2 = 1 / (1 + np.exp(-a2))\n",
    "                else: # ハイパボリックタンジェント関数\n",
    "                    z2 = np.tanh(a2)\n",
    "\n",
    "#                 print(\"z2 : {}、出力 (batch_size, n_nodes2)\".format(z2.shape)) # z2 : 出力 (batch_size, n_nodes2)\n",
    "\n",
    "                ### 3層目\n",
    "#                 print(\"===== フォワードプロバゲーション 3層 =============================================\")\n",
    "#                 w3 = sigma * np.random.randn(self.n_nodes2, self.n_output)  # 重み\n",
    "                a3 = z2 @ self.w3 + self.b3 # 出力 (batch_size, n_output)\n",
    "                # ソフトマックス関数\n",
    "                z3 = (np.exp(a3) / np.sum(np.exp(a3)))\n",
    "#                 z3 = 0\n",
    "#                 for i in range(n_output):\n",
    "#                     z3 += (np.exp(a3[:,i])) / np.sum(np.exp(a3))\n",
    "\n",
    "#                 print(\"z3 : {}、出力 (batch_size, n_output)\".format(z3.shape)) # z3 : 出力 (batch_size, n_output)\n",
    "\n",
    "                ### バックプロバゲーション\n",
    "                ### 3層目\n",
    "#                 print(\"===== バックプロバゲーション 3層 =============================================\")\n",
    "                slope_L_a3 = (1 / mini_X_train.shape[0]) * (z3 - mini_y_train)\n",
    "                slope_L_b3 = sum(slope_L_a3)\n",
    "                slope_L_w3 = z2.T @ slope_L_a3\n",
    "                slope_L_z2 = slope_L_a3 @ self.w3.T\n",
    "\n",
    "#                 print(slope_L_a3)\n",
    "#                 print(slope_L_b3)\n",
    "#                 print(slope_L_w3)\n",
    "#                 print(slope_L_z2)\n",
    "\n",
    "                ### 2層目\n",
    "#                 print(\"===== バックプロバゲーション 2層 =============================================\")\n",
    "                slope_L_a2 = slope_L_z2 * (1 - (np.tanh(a2) ** 2))\n",
    "                slope_L_b2 = sum(slope_L_a2)\n",
    "                slope_L_w2 = z1.T @ slope_L_a2\n",
    "                slope_L_z1 = slope_L_a2 @ self.w2.T\n",
    "\n",
    "#                 print(slope_L_a2)\n",
    "#                 print(slope_L_b2)\n",
    "#                 print(slope_L_w2)\n",
    "#                 print(slope_L_z1)\n",
    "\n",
    "                ### 1層目\n",
    "                slope_L_a1 = slope_L_z1 * (1 - (np.tanh(a1) ** 2))\n",
    "                slope_L_b1 = sum(slope_L_a1)\n",
    "                slope_L_w1 = mini_X_train.T @ slope_L_a1\n",
    "\n",
    "                # 重みを更新\n",
    "#                 print(\"===== 重みの更新 =============================================\")\n",
    "#                 print(\"= w1 =\")\n",
    "#                 print(w1)\n",
    "#                 print(\"= slope_L_w1 =\")\n",
    "#                 print(slope_L_w1)\n",
    "\n",
    "                # 重みの更新\n",
    "                self.w1 = self.w1 - (self.alpha * slope_L_w1)\n",
    "                self.w2 = self.w2 - (self.alpha * slope_L_w2)\n",
    "                self.w3 = self.w3 - (self.alpha * slope_L_w3)\n",
    "\n",
    "                # バイアス項の更新\n",
    "                self.b1 = self.b1 - (self.alpha * slope_L_b1)\n",
    "                self.b2 = self.b2 - (self.alpha * slope_L_b2)\n",
    "                self.b3 = self.b3 - (self.alpha * slope_L_b3)\n",
    "\n",
    "#                 print(\"===== バックプロバゲーション 1層 =============================================\")\n",
    "#                 print(slope_L_a1)\n",
    "#                 print(slope_L_b1)\n",
    "#                 print(slope_L_w1)\n",
    "            # 交差エントロピー\n",
    "            cee_L = self._cross_entropy_error(mini_y_train, z3)\n",
    "            self.cee_array.append(cee_L)\n",
    "\n",
    "    def _cross_entropy_error(self, mini_y_train, z3):\n",
    "        # エラーを起こさないための微小値\n",
    "        delta = 1e-7\n",
    "\n",
    "        # 交差エントロピー誤差の計算\n",
    "        cee = 0\n",
    "        for j in range(mini_y_train.shape[0]):\n",
    "            for k in range(self.n_output):\n",
    "                cee += mini_y_train[j,k] * np.log(z3[j,k] + delta)\n",
    "#         cee = -1 * np.sum((1 / self.batch_size) * np.log(z3 + delta))\n",
    "#         cee = -1 * / mini_y_train.shape[0] * (np.sum((1 / mini_y_train.shape[0]) * np.log(z3 + delta))\n",
    "        cee = -1 * cee / mini_y_train.shape[0]\n",
    "\n",
    "        return cee\n",
    "\n",
    "#         if self.verbose:\n",
    "#             #verboseをTrueにした際は学習過程などを出力する\n",
    "#             print()\n",
    "#         pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        \n",
    "        ### フォワードプロバゲーション\n",
    "        # 1層\n",
    "        a1 = X @ self.w1 + self.b1\n",
    "        z1 = 1 / (1 + np.exp(-1 * a1))\n",
    "        # 2層\n",
    "        a2 = z1 @ self.w2 + self.b2\n",
    "        z2 = 1 / (1 + np.exp(-1 * a2))\n",
    "        # 3層\n",
    "        a3 = z2 @ self.w3 + self.b3\n",
    "        z3 = (np.exp(a3) / np.sum(np.exp(a3)))\n",
    "#         print(\"self.w1 : {}\".format(self.w1.shape))\n",
    "#         print(\"self.b1 : {}\".format(self.b1.shape))\n",
    "#         print(\"self.w2 : {}\".format(self.w2.shape))\n",
    "#         print(\"self.b2 : {}\".format(self.b2.shape))\n",
    "#         print(\"self.w3 : {}\".format(self.w3.shape))\n",
    "#         print(\"self.b3 : {}\".format(self.b3.shape))\n",
    "#         print(\"self.a1 : {}\".format(a1.shape))\n",
    "#         print(\"self.a2 : {}\".format(a2.shape))\n",
    "#         print(\"self.a3 : {}\".format(a3.shape))\n",
    "#         print(\"self.z1 : {}\".format(z1.shape))\n",
    "#         print(\"self.z2 : {}\".format(z2.shape))\n",
    "#         print(\"self.z3 : {}\".format(z3.shape))\n",
    "\n",
    "        # 最も高い確率(z3内のデータ)を判定\n",
    "        max_z3_index = np.argmax(z3)\n",
    "        print(max_z3_index)\n",
    "        print(z3.flatten().shape)\n",
    "        max_z3 = z3.flatten()[max_z3_index]\n",
    "\n",
    "        return max_z3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "953bc779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特徴量ベクトル(batch_size, n_features)：(48000, 784)\n",
      "バッチサイズ(self.batch_size) : 20\n",
      "特徴量の数(self.n_features) : 784\n",
      "1層目のノード数(self.n_nodes1) : 400\n",
      "2層目のノード数(self.n_nodes2) : 200\n",
      "出力のクラス数（3層目のノード数）(self.n_output): 10\n",
      "6\n",
      "(100000,)\n",
      "1.1673089454611034e-05\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "X_train = X_train.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "# print(y_train.shape) # (60000,)\n",
    "# print(y_train_one_hot.shape) # (60000, 10)\n",
    "# print(y_train_one_hot.dtype) # float64\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)\n",
    "# print(X_train.shape) # (48000, 784)\n",
    "# print(X_val.shape) # (12000, 784)\n",
    "# print(y_train.shape) # (48000, 10)\n",
    "# print(y_val.shape) # (12000, 10)\n",
    "\n",
    "# クラス宣言時の引数\n",
    "sigma = 0.01 # ガウス分布（正規分布）用の標準偏差\n",
    "batch_size = 20 # バッチサイズ\n",
    "n_features = 784 # 特徴量の数\n",
    "n_nodes1 = 400 # 1層目のノード数\n",
    "n_nodes2 = 200 # 2層目のノード数\n",
    "n_output = 10 # 出力のクラス数（3層目のノード数）\n",
    "num_iter = 50 # イテレーション回数\n",
    "alpha = 0.000001 # 学習率\n",
    "verbose = False\n",
    "\n",
    "# fit関数呼び出し時の引数\n",
    "fp = \"sigmoid\" # sigmoid or tanh\n",
    "\n",
    "# インスタンス化\n",
    "ssnnc = ScratchSimpleNeuralNetrowkClassifier(sigma, batch_size, n_features, n_nodes1, n_nodes2, n_output, num_iter, alpha, verbose)\n",
    "# fit関数呼び出し\n",
    "ssnnc.fit(X_train, y_train, X_val, y_val, fp)\n",
    "accuracy = ssnnc.predict(X_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3883bcd8",
   "metadata": {},
   "source": [
    "### 【問題7】学習曲線のプロット\n",
    "学習曲線をプロットしてください。<br>\n",
    "ニューラルネットワークは過学習が発生しやすいため、学習曲線の確認が重要です。訓練データと検証データに対するエポックごとの損失（交差エントロピー誤差）を記録できるようにする必要があります。<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "551c276b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(ssnnc.cee_array)), ssnnc.cee_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf912b61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
